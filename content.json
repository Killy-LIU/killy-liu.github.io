[{"title":"不看任何数学公式的情况下理解傅里叶分析","date":"2017-08-14T14:17:45.000Z","path":"2017/08/14/不看任何数学公式的情况下理解傅里叶分析/","text":"转载自：韩 昊 https://zhuanlan.zhihu.com/p/19763358谨以此文献给大连海事大学的吴楠老师，柳晓鸣老师，王新年老师以及张晶泊老师。 &emsp;&emsp;傅里叶分析不仅仅是一个数学工具，更是一种可以彻底颠覆一个人以前世界观的思维模式。但不幸的是，傅里叶分析的公式看起来太复杂了，所以很多大一新生上来就懵圈并从此对它深恶痛绝。老实说，这么有意思的东西居然成了大学里的杀手课程，不得不归咎于编教材的人实在是太严肃了。（您把教材写得好玩一点会死吗？会死吗？）所以我一直想写一个有意思的文章来解释傅里叶分析，有可能的话高中生都能看懂的那种。所以，不管读到这里的您从事何种工作，我保证您都能看懂，并且一定将体会到通过傅里叶分析看到世界另一个样子时的快感。至于对于已经有一定基础的朋友，也希望不要看到会的地方就急忙往后翻，仔细读一定会有新的发现。————以上是定场诗———— 下面进入正题： 抱歉，还是要啰嗦一句：其实学习本来就不是易事，我写这篇文章的初衷也是希望大家学习起来更加轻松，充满乐趣。但是千万！千万不要把这篇文章收藏起来，或是存下地址，心里想着：以后有时间再看。这样的例子太多了，也许几年后你都没有再打开这个页面。无论如何，耐下心，读下去。这篇文章要比读课本要轻松、开心得多…… p.s.本文无论是cos还是sin，都统一用“正弦波”（Sine Wave）一词来代表简谐波。 一、什么是频域从我们出生，我们看到的世界都以时间贯穿，股票的走势、人的身高、汽车的轨迹都会随着时间发生改变。这种以时间作为参照来观察动态世界的方法我们称其为时域分析。而我们也想当然的认为，世间万物都在随着时间不停的改变，并且永远不会静止下来。但如果我告诉你，用另一种方法来观察世界的话，你会发现世界是永恒不变的，你会不会觉得我疯了？我没有疯，这个静止的世界就叫做频域。 先举一个公式上并非很恰当，但意义上再贴切不过的例子： 在你的理解中，一段音乐是什么呢？ 这是我们对音乐最普遍的理解，一个随着时间变化的震动。但我相信对于乐器小能手们来说，音乐更直观的理解是这样的： 好的！下课，同学们再见。 是的，其实这一段写到这里已经可以结束了。上图是音乐在时域的样子，而下图则是音乐在频域的样子。所以频域这一概念对大家都从不陌生，只是从来没意识到而已。 现在我们可以回过头来重新看看一开始那句痴人说梦般的话：世界是永恒的。 将以上两图简化： 时域： 频域： 在时域，我们观察到钢琴的琴弦一会上一会下的摆动，就如同一支股票的走势；而在频域，只有那一个永恒的音符。 所以 你眼中看似落叶纷飞变化无常的世界，实际只是躺在上帝怀中一份早已谱好的乐章。抱歉，这不是一句鸡汤文，而是黑板上确凿的公式：傅里叶同学告诉我们，任何周期函数，都可以看作是不同振幅，不同相位正弦波的叠加。在第一个例子里我们可以理解为，利用对不同琴键不同力度，不同时间点的敲击，可以组合出任何一首乐曲。 而贯穿时域与频域的方法之一，就是传中说的傅里叶分析。傅里叶分析可分为傅里叶级数（Fourier Serie）和傅里叶变换(Fourier Transformation)，我们从简单的开始谈起。 二、傅里叶级数(Fourier Series)的频谱还是举个栗子并且有图有真相才好理解。 如果我说我能用前面说的正弦曲线波叠加出一个带90度角的矩形波来，你会相信吗？你不会，就像当年的我一样。但是看看下图： 第一幅图是一个郁闷的正弦波cos（x） 第二幅图是2个卖萌的正弦波的叠加cos(x)+a.cos(3x) 第三幅图是4个发春的正弦波的叠加 第四幅图是10个便秘的正弦波的叠加 随着正弦波数量逐渐的增长，他们最终会叠加成一个标准的矩形，大家从中体会到了什么道理？ （只要努力，弯的都能掰直！） 随着叠加的递增，所有正弦波中上升的部分逐渐让原本缓慢增加的曲线不断变陡，而所有正弦波中下降的部分又抵消了上升到最高处时继续上升的部分使其变为水平线。一个矩形就这么叠加而成了。但是要多少个正弦波叠加起来才能形成一个标准90度角的矩形波呢？不幸的告诉大家，答案是无穷多个。（上帝：我能让你们猜着我？） 不仅仅是矩形，你能想到的任何波形都是可以如此方法用正弦波叠加起来的。这是没有接触过傅里叶分析的人在直觉上的第一个难点，但是一旦接受了这样的设定，游戏就开始有意思起来了。 还是上图的正弦波累加成矩形波，我们换一个角度来看看： 在这几幅图中，最前面黑色的线就是所有正弦波叠加而成的总和，也就是越来越接近矩形波的那个图形。而后面依不同颜色排列而成的正弦波就是组合为矩形波的各个分量。这些正弦波按照频率从低到高从前向后排列开来，而每一个波的振幅都是不同的。一定有细心的读者发现了，每两个正弦波之间都还有一条直线，那并不是分割线，而是振幅为0的正弦波！也就是说，为了组成特殊的曲线，有些正弦波成分是不需要的。 这里，不同频率的正弦波我们成为频率分量。 好了，关键的地方来了！！ 如果我们把第一个频率最低的频率分量看作“1”，我们就有了构建频域的最基本单元。 对于我们最常见的有理数轴，数字“1”就是有理数轴的基本单元。 时域的基本单元就是“1秒”，如果我们将一个角频率为\\omega{0} 的正弦波cos（\\omega{0} t）看作基础，那么频域的基本单元就是\\omega_{0} 。 有了“1”，还要有“0”才能构成世界，那么频域的“0”是什么呢？cos（0t）就是一个周期无限长的正弦波，也就是一条直线！所以在频域，0频率也被称为直流分量，在傅里叶级数的叠加中，它仅仅影响全部波形相对于数轴整体向上或是向下而不改变波的形状。 接下来，让我们回到初中，回忆一下已经死去的八戒，啊不，已经死去的老师是怎么定义正弦波的吧。 正弦波就是一个圆周运动在一条直线上的投影。所以频域的基本单元也可以理解为一个始终在旋转的圆知乎不能传动态图真是太让人惋惜了…… 想看动图的同学请戳这里： File:Fourier series square wave circles animation.gif 以及这里： File:Fourier series sawtooth wave circles animation.gif 点出去的朋友不要被wiki拐跑了，wiki写的哪有这里的文章这么没节操是不是。 介绍完了频域的基本组成单元，我们就可以看一看一个矩形波，在频域里的另一个模样了： 这是什么奇怪的东西？ 这就是矩形波在频域的样子，是不是完全认不出来了？教科书一般就给到这里然后留给了读者无穷的遐想，以及无穷的吐槽，其实教科书只要补一张图就足够了：频域图像，也就是俗称的频谱，就是—— 再清楚一点：可以发现，在频谱中，偶数项的振幅都是0，也就对应了图中的彩色直线。振幅为0的正弦波。 动图请戳： File:Fourier series and transform.gif 老实说，在我学傅里叶变换时，维基的这个图还没有出现，那时我就想到了这种表达方法，而且，后面还会加入维基没有表示出来的另一个谱——相位谱。 但是在讲相位谱之前，我们先回顾一下刚刚的这个例子究竟意味着什么。记得前面说过的那句“世界是静止的”吗？估计好多人对这句话都已经吐槽半天了。想象一下，世界上每一个看似混乱的表象，实际都是一条时间轴上不规则的曲线，但实际这些曲线都是由这些无穷无尽的正弦波组成。我们看似不规律的事情反而是规律的正弦波在时域上的投影，而正弦波又是一个旋转的圆在直线上的投影。那么你的脑海中会产生一个什么画面呢？ 我们眼中的世界就像皮影戏的大幕布，幕布的后面有无数的齿轮，大齿轮带动小齿轮，小齿轮再带动更小的。在最外面的小齿轮上有一个小人——那就是我们自己。我们只看到这个小人毫无规律的在幕布前表演，却无法预测他下一步会去哪。而幕布后面的齿轮却永远一直那样不停的旋转，永不停歇。这样说来有些宿命论的感觉。说实话，这种对人生的描绘是我一个朋友在我们都是高中生的时候感叹的，当时想想似懂非懂，直到有一天我学到了傅里叶级数…… 三、傅里叶级数（Fourier Series）的相位谱上一章的关键词是：从侧面看。这一章的关键词是：从下面看。 在这一章最开始，我想先回答很多人的一个问题：傅里叶分析究竟是干什么用的？这段相对比较枯燥，已经知道了的同学可以直接跳到下一个分割线。 先说一个最直接的用途。无论听广播还是看电视，我们一定对一个词不陌生——频道。频道频道，就是频率的通道，不同的频道就是将不同的频率作为一个通道来进行信息传输。下面大家尝试一件事： 先在纸上画一个sin（x），不一定标准，意思差不多就行。不是很难吧。 好，接下去画一个sin（3x）+sin（5x）的图形。 别说标准不标准了，曲线什么时候上升什么时候下降你都不一定画的对吧？ 好，画不出来不要紧，我把sin（3x）+sin（5x）的曲线给你，但是前提是你不知道这个曲线的方程式，现在需要你把sin（5x）给我从图里拿出去，看看剩下的是什么。这基本是不可能做到的。 但是在频域呢？则简单的很，无非就是几条竖线而已。 所以很多在时域看似不可能做到的数学操作，在频域相反很容易。这就是需要傅里叶变换的地方。尤其是从某条曲线中去除一些特定的频率成分，这在工程上称为滤波，是信号处理最重要的概念之一，只有在频域才能轻松的做到。 再说一个更重要，但是稍微复杂一点的用途——求解微分方程。（这段有点难度，看不懂的可以直接跳过这段）微分方程的重要性不用我过多介绍了。各行各业都用的到。但是求解微分方程却是一件相当麻烦的事情。因为除了要计算加减乘除，还要计算微分积分。而傅里叶变换则可以让微分和积分在频域中变为乘法和除法，大学数学瞬间变小学算术有没有。 傅里叶分析当然还有其他更重要的用途，我们随着讲随着提。 ———————————————————————————————————— 下面我们继续说相位谱： 通过时域到频域的变换，我们得到了一个从侧面看的频谱，但是这个频谱并没有包含时域中全部的信息。因为频谱只代表每一个对应的正弦波的振幅是多少，而没有提到相位。基础的正弦波A.sin(wt+θ)中，振幅，频率，相位缺一不可，不同相位决定了波的位置，所以对于频域分析，仅仅有频谱（振幅谱）是不够的，我们还需要一个相位谱。那么这个相位谱在哪呢？我们看下图，这次为了避免图片太混论，我们用7个波叠加的图。 鉴于正弦波是周期的，我们需要设定一个用来标记正弦波位置的东西。在图中就是那些小红点。小红点是距离频率轴最近的波峰，而这个波峰所处的位置离频率轴有多远呢？为了看的更清楚，我们将红色的点投影到下平面，投影点我们用粉色点来表示。当然，这些粉色的点只标注了波峰距离频率轴的距离，并不是相位。 这里需要纠正一个概念：时间差并不是相位差。如果将全部周期看作2Pi或者360度的话，相位差则是时间差在一个周期中所占的比例。我们将时间差除周期再乘2Pi，就得到了相位差。 在完整的立体图中，我们将投影得到的时间差依次除以所在频率的周期，就得到了最下面的相位谱。所以，频谱是从侧面看，相位谱是从下面看。下次偷看女生裙底被发现的话，可以告诉她：“对不起，我只是想看看你的相位谱。” 注意到，相位谱中的相位除了0，就是Pi。因为cos（t+Pi）=-cos（t），所以实际上相位为Pi的波只是上下翻转了而已。对于周期方波的傅里叶级数，这样的相位谱已经是很简单的了。另外值得注意的是，由于cos（t+2Pi）=cos（t），所以相位差是周期的，pi和3pi，5pi，7pi都是相同的相位。人为定义相位谱的值域为(-pi，pi]，所以图中的相位差均为Pi。 最后来一张大集合： 四、傅里叶变换（Fourier Transformation）相信通过前面三章，大家对频域以及傅里叶级数都有了一个全新的认识。但是文章在一开始关于钢琴琴谱的例子我曾说过，这个栗子是一个公式错误，但是概念典型的例子。所谓的公式错误在哪里呢？ 傅里叶级数的本质是将一个周期的信号分解成无限多分开的（离散的）正弦波，但是宇宙似乎并不是周期的。曾经在学数字信号处理的时候写过一首打油诗： 往昔连续非周期，回忆周期不连续，任你ZT、DFT，还原不回去。（请无视我渣一样的文学水平……） 在这个世界上，有的事情一期一会，永不再来，并且时间始终不曾停息地将那些刻骨铭心的往昔连续的标记在时间点上。但是这些事情往往又成为了我们格外宝贵的回忆，在我们大脑里隔一段时间就会周期性的蹦出来一下，可惜这些回忆都是零散的片段，往往只有最幸福的回忆，而平淡的回忆则逐渐被我们忘却。因为，往昔是一个连续的非周期信号，而回忆是一个周期离散信号。 是否有一种数学工具将连续非周期信号变换为周期离散信号呢？抱歉，真没有。 比如傅里叶级数，在时域是一个周期且连续的函数，而在频域是一个非周期离散的函数。这句话比较绕嘴，实在看着费事可以干脆回忆第一章的图片。 而在我们接下去要讲的傅里叶变换，则是将一个时域非周期的连续信号，转换为一个在频域非周期的连续信号。 算了，还是上一张图方便大家理解吧： 或者我们也可以换一个角度理解：傅里叶变换实际上是对一个周期无限大的函数进行傅里叶变换。 所以说，钢琴谱其实并非一个连续的频谱，而是很多在时间上离散的频率，但是这样的一个贴切的比喻真的是很难找出第二个来了。 因此在傅里叶变换在频域上就从离散谱变成了连续谱。那么连续谱是什么样子呢？ 你见过大海么？为了方便大家对比，我们这次从另一个角度来看频谱，还是傅里叶级数中用到最多的那幅图，我们从频率较高的方向看。 以上是离散谱，那么连续谱是什么样子呢？ 尽情的发挥你的想象，想象这些离散的正弦波离得越来越近，逐渐变得连续…… 直到变得像波涛起伏的大海： 很抱歉，为了能让这些波浪更清晰的看到，我没有选用正确的计算参数，而是选择了一些让图片更美观的参数，不然这图看起来就像屎一样了。 不过通过这样两幅图去比较，大家应该可以理解如何从离散谱变成了连续谱的了吧？原来离散谱的叠加，变成了连续谱的累积。所以在计算上也从求和符号变成了积分符号。 不过，这个故事还没有讲完，接下去，我保证让你看到一幅比上图更美丽壮观的图片，但是这里需要介绍到一个数学工具才能然故事继续，这个工具就是—— 五、宇宙耍帅第一公式：欧拉公式虚数i这个概念大家在高中就接触过，但那时我们只知道它是-1的平方根，可是它真正的意义是什么呢? 这里有一条数轴，在数轴上有一个红色的线段，它的长度是1。当它乘以3的时候，它的长度发生了变化，变成了蓝色的线段，而当它乘以-1的时候，就变成了绿色的线段，或者说线段在数轴上围绕原点旋转了180度。 我们知道乘-1其实就是乘了两次 i使线段旋转了180度，那么乘一次 i 呢——答案很简单——旋转了90度。 同时，我们获得了一个垂直的虚数轴。实数轴与虚数轴共同构成了一个复数的平面，也称复平面。这样我们就了解到，乘虚数i的一个功能——旋转。 现在，就有请宇宙第一耍帅公式欧拉公式隆重登场—— 这个公式在数学领域的意义要远大于傅里叶分析，但是乘它为宇宙第一耍帅公式是因为它的特殊形式——当x等于Pi的时候。 经常有理工科的学生为了跟妹子表现自己的学术功底，用这个公式来给妹子解释数学之美：”石榴姐你看，这个公式里既有自然底数e，自然数1和0，虚数i还有圆周率pi，它是这么简洁，这么美丽啊！“但是姑娘们心里往往只有一句话：”臭屌丝……“ 这个公式关键的作用，是将正弦波统一成了简单的指数形式。我们来看看图像上的涵义： 欧拉公式所描绘的，是一个随着时间变化，在复平面上做圆周运动的点，随着时间的改变，在时间轴上就成了一条螺旋线。如果只看它的实数部分，也就是螺旋线在左侧的投影，就是一个最基础的余弦函数。而右侧的投影则是一个正弦函数。 关于复数更深的理解，大家可以参考： 复数的物理意义是什么？ 这里不需要讲的太复杂，足够让大家理解后面的内容就可以了。 六、指数形式的傅里叶变换有了欧拉公式的帮助，我们便知道：正弦波的叠加，也可以理解为螺旋线的叠加在实数空间的投影。而螺旋线的叠加如果用一个形象的栗子来理解是什么呢？ 光波 高中时我们就学过，自然光是由不同颜色的光叠加而成的，而最著名的实验就是牛顿师傅的三棱镜实验： 所以其实我们在很早就接触到了光的频谱，只是并没有了解频谱更重要的意义。 但不同的是，傅里叶变换出来的频谱不仅仅是可见光这样频率范围有限的叠加，而是频率从0到无穷所有频率的组合。 这里，我们可以用两种方法来理解正弦波： 第一种前面已经讲过了，就是螺旋线在实轴的投影。 另一种需要借助欧拉公式的另一种形式去理解： e^{it}=cos(t)+i.sin(t)e^{-it}=cos(t)-i.sin(t)将以上两式相加再除2，得到： cos(t)=\\frac{e^{it}+e^{-it}}{2}这个式子可以怎么理解呢？ 我们刚才讲过，e^(it)可以理解为一条逆时针旋转的螺旋线，那么e^(-it)则可以理解为一条顺时针旋转的螺旋线。而cos(t)则是这两条旋转方向不同的螺旋线叠加的一半，因为这两条螺旋线的虚数部分相互抵消掉了！ 举个例子的话，就是极化方向不同的两束光波，磁场抵消，电场加倍。 这里，逆时针旋转的我们称为正频率，而顺时针旋转的我们称为负频率（注意不是复频率）。 好了，刚才我们已经看到了大海——连续的傅里叶变换频谱，现在想一想，连续的螺旋线会是什么样子： 想象一下再往下翻： | | | | | | | | | 是不是很漂亮？ 你猜猜，这个图形在时域是什么样子？ 哈哈，是不是觉得被狠狠扇了一个耳光。数学就是这么一个把简单的问题搞得很复杂的东西。 顺便说一句，那个像大海螺一样的图，为了方便观看，我仅仅展示了其中正频率的部分，负频率的部分没有显示出来。 如果你认真去看，海螺图上的每一条螺旋线都是可以清楚的看到的，每一条螺旋线都有着不同的振幅（旋转半径），频率（旋转周期）以及相位。而将所有螺旋线连成平面，就是这幅海螺图了。 好了，讲到这里，相信大家对傅里叶变换以及傅里叶级数都有了一个形象的理解了，我们最后用一张图来总结一下： 本文只是介绍了一种对傅里叶分析新颖的理解方法，对于求学，还是要踏踏实实弄清楚公式和概念，学习，真的没有捷径。但至少通过本文，我希望可以让这条漫长的路变得有意思一些。 最后，祝大家都能在学习中找到乐趣。…","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"信号","slug":"信号","permalink":"http://blog.killyliu.com/tags/信号/"}]},{"title":"看似推理题，实则情感题","date":"2017-07-09T09:29:05.000Z","path":"2017/07/09/看似推理题，实则情感题/","text":"我以为我找到了真相，却原来是你给的假象。我以为我爱得高尚，不过是自以为是的虚妄。我以为用完全的牺牲就能成全你的幸福，却忽略了你想要的幸福不是这般模样。我们都是这个庸俗世界里的机械齿轮，大多数时间里都重复着同样的工作。而唯一的精彩就是情感让我们彼此连结。&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;–《嫌疑人X的献身》 狭路相逢，棋逢对手这个故事的两大主角：孤傲清高一尘不染的学者型 — 唐川孤僻邋遢不善社交的怪咖型 — 石泓 一个阳光、正派、磊落、勇于追求美好生活；一个阴郁、自闭、纠结、不敢表达自己；他们在心里佩服着对方同时也暗自和对方较着劲。最好的朋友也是最大的敌人。 从他们认识到最后，都没有变过。解开难题的真相与献身的失败，看起来是唐川赢了，石泓输了。可其实，他们谁也没有赢。 【石泓说，不是走出去，而是走下去。】不修边幅、一成不变、毫无鲜活之气的灰败人生。以为这冰冷的，看不到希望的，没有色彩的生活，由出生开始，一路相随。就在最浓烈的绝望里，他体会到了一丝暖意，一抹亮色。“有些人仅仅是存在就足以拯救某个人。”究竟是神的恩赐，还是魔鬼的惩罚。他说那些河滩旁的人，都是无用的齿轮，他们一层不变，毫无建树，可有可无，挣扎在生活火热中。他大概在他们身上，看到了自己的悲剧。不算高的理想，却也是够不到的。永远孤独的旁观者，哪里敢奢望幸福呢！流水中的落叶，旋转着旋转着，还是顺流而下了。那个天才的、孤僻的、怪异的边缘人。 【唐川说，如果真相会令所有人都痛苦，那么找寻真相的意义又是什么。】唐川是一个非常温暖的天才，对整个世界报之以真诚。会对好友买的早餐窝心一笑，会对街边的乞丐有所施舍，会对琳琅的套餐图片笑着说看起来都很好吃，会对多年不见的老友热情相待，打破隔阂，在家吃饭，感叹唐川问他还打羽毛吗？石泓说不打了，他偶尔会爬爬山。山的包容在于，一个人置身进去，会觉得和整个自然融合，心就不会那么孤单。而打羽毛，却要是两个人的活动。伪装成推理问题而实为情感问题的盲点问题，太难了。而唐川最后双手推开大门朝着明亮的阳光大步走去，告诉了我们他的答案。看见他就算遍体鳞伤，也仍要坚守的东西。两人的比赛，谁是赢家？ 苏对林的隐秘告白正如片中台词：“看起来是几何问题，实际上是函数问题。”1997年，23岁的苏进入《还珠格格》剧组，认识了21岁的林。一对相处愉快的男女，整整19年，被媒体怂恿在一起。可无论怎样，终究不来电。这，便是命运吧。 事实上，他们的不来电，不光在戏外，也在戏里。二十年间，合作过许多戏，共同点是–擦不出爱情的火花。爱情，兜兜转转直到最后，才大彻大悟。 “四十岁约定”宣告破碎。苏没有出席她的婚礼，对外宣称 – 筹备电影《嫌疑人x的献身》。这部电影讲的是–一个数学天才牺牲自己，把暗恋的人送入另一个靠谱男人的怀抱。电影将映，他对林心如“说”：“除了你，我想不到更适合“她”的人。”也许这便是他心中所想。借此电影，为两人长达20年的暧昧感情，做一次表白。祝福她在“靠谱”男人身边，过得幸福。 相较而言，我不愿相信这是巧合，更相信，这是苏潜意识的选择，是命中注定。正如普希金所言：“男女之间没有友谊，所谓的友谊，只是爱情的开始，或者爱情的结束。”众目睽睽下，苏祭奠了自己已经失去的爱情。","tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.killyliu.com/tags/随笔/"}]},{"title":"和梦想的近身肉搏 -- 记忆中的技术，眼中的情怀","date":"2017-06-23T07:02:24.000Z","path":"2017/06/23/遇见你，很幸运-—-致《摔跤吧，爸爸》/","text":"&emsp;&emsp;自上映起，《摔跤吧，爸爸》就陆陆续续俘获了不少男女老少影迷，这次已经是三刷，依旧没出息的哭了。我们得意于打败了巨人，却不知巨人已老。影片虽然满是套路却又那么真诚，乖张情节中的父爱荣光更加闪亮耀眼，遇见你，很幸运。 无数望女成凤的剪影 妻子说：她们受伤了怎么版？爸爸说：那就治好她们。 妻子说：如果村子里的人说闲话怎么办？爸爸说：不用在意他们。 妻子说：以后谁会娶我们的女儿呢？爸爸说：我把她们培养出色，她们就有权选择自己的丈夫。 教练说：不要输的太难看。爸爸说：你不会输！ 教练说：至少要拿块奖牌。爸爸说：你注定是冠军！ 教练说：你已经领先了，注意防守。爸爸说：忘掉领先，保持进攻！ 教练说：有些人，注定不是打国际比赛的料。爸爸说：你输掉的，是本该你赢的比赛。 教练说：现在你至少可以有一块银牌了。爸爸说：赢下金牌，你将成为印度的榜样，永载史册！ 教练培养的姐姐，说：这里是娱乐室，可以看电视。爸爸培养的妹妹，问：训练场在哪？ 爸爸培养的吉塔，第一次参加比赛，挑选最强的对手；输了以后，彻夜难眠，问爸爸，我什么时候能再打？教练培养的吉塔，输了第一次国际比赛，脸上却没有丝毫沮丧，一心涂着漂亮的指甲油。 一个只追求拿到奖牌的教练，追求的是完成任务，享受自己是国家队教练的满足感；一个对吉塔抱有最大信心的爸爸，知道她注定是冠军，他要帮她赢，不顾一切。 偏见上的反偏见狂欢&emsp;&emsp;“我演电影时，在不同的角色中，体验过不同的人生。还有另一种人生，就是我自己的人生：卸去演员的身份，作为一个人，以我的方式存在。生活中，思绪如风般吹拂着我的脑海。我读报纸、看新闻、与朋友闲聊、和陌生人交谈，总有一些事触动我的心弦。” &emsp;&emsp;“一方面，印度在崛起，蒸蒸日上，作为一个印度人，我感到高兴和自豪。但是，在社会中还有很多令人心酸的事实，我们却对此熟视无睹。这些苦难，却让我深感不安，感到哀伤。有时我会想，干嘛要去思考这些与我无关的事情呢？我的生活幸福美满，别人的苦难与我何干呢？但是它确有干系。因为我也是这个社会中的一份子。一连串的事情把你我和社会的每一个人都联系在一起，一呼一吸中，体会心中的共鸣。” &emsp;&emsp;“我想讨论一些关系印度民生的话题，不责难任何人，不中伤任何人，也不制约任何人。人人都说，伤害我们的人近在咫尺，或许我们都有责任。现在，与我一起踏上这段旅程吧。一起去寻找、去发现、去学习、去分享，一起去揭开这些难题的谜底。” &emsp;&emsp;“我无心激化矛盾，只为能改变这个时代。无论是谁的心中，只要有星星之火，必将成燎原之势。” &emsp;&emsp;“拍电影不是用来迎合谁的。其实当你拍摄了一部对自己国家有一定批判意义的电影时，这对国家就有着至关重要的意义。批判自己和自己的国家是我们进步的第一步。没必要为自己的祖国被放在聚光灯下而羞耻，应该羞耻的是我们的国家在那一方面还有欠缺。” &emsp;&emsp;我们手中选择的权利，因太轻易而不被珍惜，却是其他人梦寐以求的希望。我想不到用什么情绪，去唤醒那些不以为然的懒散。阻止前行的可能不只是自己，但若失掉一颗想赢的心，未免太过让人失望。 阿米尔·汗 —— 天道酬勤，厚积薄发&emsp;&emsp;作为一个演员，阿米尔·汗完美演绎了一个怀抱理想的摔跤手的三个年龄段：拍完青年戏，增肥56斤；拍老年戏之后，5个月瘦掉50斤，将体脂率从37%下降到9.6%；拍壮年戏时，已然是近于健美的身材。 &emsp;&emsp;身材之外，更加关注的是米叔的眼神变化。 &emsp;&emsp;青年时期，那眼神里跳跃着的是对喜爱的摔跤运动的志在必得和对这个世界的狂热，明亮、清澈。 &emsp;&emsp;中年时期，开始沉淀，挣扎，但仍然执着，眼神充满着坚毅. &emsp;&emsp;暮年时期，仍有愤怒但却无奈，一直为之努力奋斗的理想并不会给自己带来平和的人生，但他开始接受这个世界的不公平，只是即便是接受，也不愿意放弃，因而眼神开始沧桑，但仍然有力量。 &emsp;&emsp;米叔的人生不是什么开挂，他只是比别的人都明白，选择和努力的重要性。","tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.killyliu.com/tags/随笔/"}]},{"title":"四六级·神吐槽","date":"2017-06-17T07:25:42.000Z","path":"2017/06/17/四六级·神吐槽/","text":"&emsp;&emsp;上联：发下卷子正心凉，一紧张，词全忘，似曾相识，何意却不详。&emsp;&emsp;&emsp;&emsp;&emsp;听力词汇两茫茫，看阅读，泪千行。&emsp;&emsp;下联：步出考场见同窗，都一样，很受伤，如此成绩，无颜见爹娘。&emsp;&emsp;&emsp;&emsp;&emsp;只待明朝发榜日，接绳套，系房梁。&emsp;&emsp;横批：怎一个苦字了得 考完四六级，我们都是段子手@隐淼：今天的六级听力，我是这样的 @锦瑟暖时光：上联：卖书卖车卖电脑下联：长江黄河珠三角横批：防不胜防来来来，看一看呐，走过路过不要错过。买书的去长江，买车的去黄河，买电脑的去珠三角啊~ @不会流泪的眼：考六级就像逛海澜之家，一年两次，每次都有新感觉。 @荒途10096235：每年的翻译都是各种人才尽出，去年有个同学汤不会写，翻译成含有叶子的水，今年有人风筝不会写，翻译成飞着的纸片，还记得自己高中写作文葬礼不会写，最后翻译成死去的老人的派对。。。。 @Mr李小博考试之前：还是听天由命吧！考试前期：好好答还是能过！考试中期：我有一句MMP！考试后期：为何没好好复习！考试之后：拉倒吧12月再见！ @山东师范大学团委：上联：长江黄河珠江，卖书卖车卖电脑下联：唐朝宋朝明朝，文理出国上大学横批：12月再见 @xxteukxx：听力真的跟题目有关系吗选词填空配对阅读还有阅读题在讲什么本来看到翻译题是唐朝内心还窃喜了一会社会秩序稳定？大概是people’s life is happy我觉得我的推理还是很有道理的李白你不是刺客嘛为什么要和杜甫一起写诗 @刘欢uan：我以为上次六级没看懂题目就够惨了，没想到更惨的是这次只看懂题目 @VIVO：长江长江，我是黄河黄河黄河，我是珠江珠江珠江，我是长江卖书卖电脑卖自行车这是要凑路费出去跳江吗 @wzm考生：关于选词填空有一种迷茫叫做，看懂了全文，看懂了单词但是还是填不出来有一种彷徨叫做，明白了词性，明白了选项但是还是要靠猜 @郑州校园：距四六级考试还有182天，我没有裸考我今天做了一套真题 等成绩下来，你上榜了么&emsp;&emsp;四六级过了没？？过了！！过了？？过了把瘾。。 &emsp;&emsp;宇宙学生圈的圈姐总结了《全国高校四六级平均分排行top200》榜单，对照一下呗 &emsp;&emsp;然而，真正觉得遗憾的，大概是每年都会有一群考生考完试在微博上喊着“考试太难，准备二刷”，但是第二年裸考的依然是同一批人吧。","tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.killyliu.com/tags/随笔/"}]},{"title":"情不知所起，丝丝心动有点甜","date":"2017-06-10T06:04:18.000Z","path":"2017/06/10/情不知所起，丝丝心动有点甜/","text":"&emsp;&emsp;上个月在影院看《喜欢你》的时候就被他们的甜蜜气氛所感染，爱情最开始的模样，就是这份小确幸。在一起，简简单单就好。前两天莹向我推荐了一种微波炉泡面制法，相似的时间与温度把控，食与色之间的微妙平衡，莫然勾起了再看一次电影的想法，重温一场美食和爱情的邂逅。 狗一样的周冬雨，遇上猫一样的金城武&emsp;&emsp;路晋和所有的霸道总裁一样，高冷、孤独、神秘、挑剔。胜男则走与总裁相配的女主的套路，邋遢、迷糊、神经大条。就这样，这个超有洁僻、泡面得分秒不差的霸道大总裁，与不讲逻辑、不按牌里出牌的任性小萝莉，因为高反差产生碰撞，恰好起了微妙的化学变化。 &emsp;&emsp;路晋在“理性”与“资本”的合谋下成长，就像吞噬周遭生存空间的松露，一切都遵循着财富的逻辑，一切都是物与物的精细化而又干瘪的联结。胜男则刚刚好是那个唤醒路晋内心“感性”的存在，让他意识到人生的真正意义，而不仅仅是感官的出口。 一饭一蔬，一期一会&emsp;&emsp;“每个人身上都有密码，食物是打开密码的钥匙，对食物挑剔的人，在乎的不仅仅是味道，他在乎的是有没有遇到解对密码的人”。美食，可以让人产生关系，而产生情感关系的，大概是不经意之间一饭一蔬。 &emsp;&emsp;在故事的开始，胜男用一道女巫汤打开了总裁的密码。它就好像是定情信物一般，是我了解你，喜欢你的开始。 &emsp;&emsp;随后，我出一题你答一题，棋逢对手，你来我往。像是高手对决，分秒间已过了数招，而看客无从知。因为拿着我钥匙的，是你。也像是喜欢一个人的过程，从我遇见你，认识你，喜欢你，了解你。感情不就是微妙到不讲逻辑，谁都不知道在哪一个时刻，关系就达到从量变到质变。 &emsp;&emsp;浪漫见于误食河豚之后的幻想之雨，两人同撑一把少女花伞，旁若无人的行走在街道上叫着闹着，放肆洒脱恣意。公交车里肩并着肩，散发的是只有恋爱才有的甜腻，定定望着路晋的眼神里又纯又灵，仿佛一眼看得到永远，仿佛一夜走得到白头。 &emsp;&emsp;而当金城武清醒过来后，没有抛下周冬雨，他假装享受着周冬雨的照顾，他心里那根看起来冷冷酷酷的防线，此时此刻柔柔软软地松动了。能够被一个男人用这样温柔的眼神看过，该是多么幸福的一件事。“该配合你演出的我尽力在表演”，原来还能有这么美好的解释。 &emsp;&emsp;”从不打不相识的“讨厌你”，到一位追一位逃的“喜欢你”。两个截然不同的人，因“美食”而慢慢走近，达到心灵的“默契”。喜欢你，就从彼此都喜欢的部分开始。这世上最坚不可摧的情感是「懂得」，别人都不懂的，你懂；懂了，还珍惜；珍惜了，就会慢慢生出无可替代的感情。那种说不清、道不明的感觉，就从不知不觉改变自己的习惯开始。 无法选择的喜欢，是爱最甜蜜的姿态&emsp;&emsp;清新甜蜜又充满活力的气质氛围搭配上海这座弥漫着小资情调的城市，让人不自觉的沉浸其中，心甘情愿的被感染，明知不真实却仍旧不愿从幻梦中醒来，爱情的奇妙和迷人，确然是这样。 &emsp;&emsp;恰如金城武所说：“我没有什么职位给你，可我身边有个位置给你”。在恋爱的世界里，“喜欢你”就是所有行为的起点和终点，是所有不理智的症结病因。简单的爱情就像简单的生活，无法定义也不需选择，只要彼此真心喜欢，自然就会在一起。有点平淡，但却夺人心魄，突如其来，出其不意，那么美好。 &emsp;&emsp;“爱”字总带着成熟的游刃有余，而“喜欢”却只有青涩的笨拙。镜头定格在手拉手的夕阳余光，裂开的嘴角高扬不下，笑意贯穿身体的每一个细胞。能清楚的感知到，空气中弥漫着甜甜的不可名状的气息，撩拨的少女心炸成一个一个粉红泡泡，这一场奇妙的爱情际遇，以美食发端，以真心结局。","tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.killyliu.com/tags/随笔/"}]},{"title":"《人民的名义》精彩语句","date":"2017-05-31T08:00:48.000Z","path":"2017/05/31/《人民的名义》精彩语句/","text":"&emsp;&emsp;一直想写一篇关于《人民的名义》的观后感想，但由于内容思想所涉及范围政治色彩较多，因而转向了总结这不电视剧中自己认为较为出彩的语句。 1.“打铁还得自身硬” 2.“你以为别人敬他酒，敬的是他的人缘，那敬的都是他手里的权利” 3.“陈海发现了这场汇报的复杂性，表面上看起来公事公办，实际上另有内容，暗涛汹涌” 4.“像你们这种人啊，党和人民就是专门用来对不起的” 5.“做人，就不能愧对天理良心；作为共产党人，就不能背叛自己的理想信念。” 6.“共产党人是为人民服务的，不是为人民币服务的。” 7.“我现在已经引起官愤了，那他们就不怕引起民愤啊” 8.“做人不可有傲气，但不可无骨气“ ”可是做人他得喘气” 9.“这件事情，我如果处理好了不加分，处理不好了反而会减分” 10.“自媒体时代的事，传统手段已经真是难以招架了” 11.“腐败给国家和人民带来的伤害，最后啊还是要以国家和人民的伤痛去消解” 12.“我们党的干部，就是从人民群众中来，然后再回到人民群众中去” 13.“什么最美，太平世界最美” 14.“其实我们所有人都非常地清楚，我们就是从娘胎里来，再到坟墓里边去” 15.“想想我的入党介绍人，还有哪些牺牲的同志们，我活得够幸福的。真的，我活得够幸福的了” 16.“那总得给他一碗饭吧？给碗饭可以，千万别让他砸了我们的锅” 17.“跟你分享成功的人呀，一定不是同甘共苦的人” 18.“你没看到世界顶级那些大富豪啊，哪个妻子漂亮了，关键是灵魂的交融” 19.“也许是意外的惊喜，也许是意外的麻烦” 20.“他专门跟我约法三章，第一不许用公款，第二不许吃老板，第三不许喝名酒，还不许用公车” 21.“我只听说过伟大的中国人民，我从来没有听说过 伟大的中国干部，或者是伟大的中国官员” 22.“其实我们女人挺简单的，只要他们心里有我们，什么缺点我们都可以容忍。” 23.“喜欢上天文学之后方知宇宙之浩渺，时空之无限。人类算什么，李达康高育良沙瑞金又算什么，不过都是蚂蚁尘埃罢了。” 24.“银行把储户当上帝，我们就是要把上访群众当上帝。” 25.“这法律啊，是老百姓保护自己权益的最后一道防线，如果这道防线被突破了那就完了，老百姓就没指望了，群体事件就会接二连三的发生。” 26.“在他看来，你打破了某种政治平衡和政治默契。” 27.“我们的检察院是人民检察院，我们的法院是人民法院，我们的公安是人民公安，要永远把人民的利益放在心上，永远。” 28.“苍蝇不叮无缝的蛋。” 29.“官场的潜规则他没必要装作不知道吧。我能叫醒一个睡着的人，但叫不醒一个装睡的人，你懂吗？” 30.“我爱着，什么也没说，只看着你，在对面微笑。我爱着，只要我心里知觉，不必知晓你心里的想法。我珍惜我的秘密，也珍惜淡淡的忧伤，那不曾化作痛苦的忧伤。我发誓，我爱着放弃你，不怀抱任何希望，但不是没有幸福。只要能怀念，就足够幸福，即使不再看到对面微笑的你。” 31.“以自己为棋子，跟神仙下棋。以生命为代价，胜了神仙半子。不敢赌的人，就没机会赢。” 32.“我希望凭我自己的努力，一步一个脚印，一步一个台阶，这样慢慢地做上来。” 33.“我替他们考验了爱情。但是你知道爱情是经受不住考验的。” 34.“这世上最难的就是装糊涂。要不怎么又难得糊涂这句话呢” 35.“你们最终还是分道扬镳，为什么，因为你们不是一路人。” 36.“你是无产者吗？你得到的是锁链，失去的将是整个人生。” 37.“人生一定要赌，一定要拼。如果你不赌的话，可能你没有丝毫赢的机会。” 38.“分手也是一种抵达，让我们彼此抵达各自的灵魂。” 39.“敢冒天下之大不韪，才是做大事的品格。我们要是不成为别人的玩物，怎么有机会让别人成为我们的玩物呢” 40.“我挣的每一分钱，都是阳光下的清白利润。” 41.“我真的不想伤害你，我又何尝愿意伤害你啊。” 42.“他一个政法委书记的政治嗅觉和警惕性都哪儿去了” 43.“千万别意气用事把人生路给走绝了好么” 44.“你是忠于爱情了，可是你忠于的是对她的爱情。” 45.“这个世界上唯一不变的真理，就是在变。随着能力的增强地位的提高权利的扩大，这一个人总是要变的。” 46.“好声音改变不了中国，也改变不了世界，还是务实好。” 47.“无私者无畏—不想升就无所谓了？” 48.“咱们社会主义中国，劳动者是有尊严的。” 49.“在温情脉脉的面纱后面，不也是一场鸿门宴吗” 50.“这种风口浪尖的时刻，该退就退。” 51.“别以为自己了不起，缺了谁地球都转。” 52.“毙敌一千自伤八百。你如果准备杀伤敌人，也得准备接受自伤啊。” 53.“岳飞为什么会死于莫须有。岳飞啊是不愿意揣摩圣意。” 54.“记忆之所以美，是因为有现实的参照。” 55.“难道说英雄难过美人关？世人都晓神仙好，只有美人忘不了。” 56.“世人都晓神仙好，只有功名忘不了。古今将相今何在，荒冢一堆草末了。”&emsp;&emsp;”世人都晓神仙好，只有金银忘不了。终朝只恨聚无多，及到多时眼闭了。” 57.“说实话，时而看透，时而又看不透，所以才会有这么多的烦恼。” 58.“对我来说，你爱我的每一天，我都是赚来的。我不要你对我负责，我只要你爱我，可以吗” 59.“你要清楚一点如果我们不付出的话，我们的下一代就要付出。” 60.“职务的进步并不必然带来领导干部思想的提纯和境界的提升。相反，贿随权集，权重势大，更容易招来那些行贿者。” 61.“在山泉水清，出山泉水浊。” 62.“一失足成千古恨，再回头已是百年身。” 63.“这是一个爱拼才会赢的时代，你如果不让别人流血泪，别人就会让你流血泪。” 64.“你们之间到底是一份什么样的爱情？” “过命的爱情。” 65.“看未来远不如看过去要看得清楚，激昂和困惑，交织在每个人的心头。” 66.“存在的，就是合理的。” 67.“人生就是这样，只有结果，没有如果。”","tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.killyliu.com/tags/随笔/"}]},{"title":"Java实现Spark词配对Wordcount计数","date":"2017-05-24T10:26:24.000Z","path":"2017/05/24/Java实现Spark词配对Wordcount计数/","text":"需求&emsp;&emsp;使用Spark实现对一个文档中的每一行的单词进行词配对计数，要求去标点符号，将大写符号统一转化成为小写单词。&emsp;&emsp;注：实现效果与上一篇博客用Hadoop的操作结果相同。&emsp;&emsp;举例说明，最初的文档为： “a a, A ba b c &emsp;&emsp;则处理后的结果为： (a a) 2(a b) 2(a c) 1(b a) 4(b c) 1(c a) 1(c b) 1 实现过程开启hadoop和spark&emsp;&emsp;进入Hadoop所在的文件夹并执行启动语句：1$ sbin/start-all.sh &emsp;&emsp;进入Spark所在的文件夹并执行启动语句：1$ sbin/start-all.sh jar包处理&emsp;&emsp;将编码程序打包成jar包进行处理 HDFS文件设置&emsp;&emsp;使用hdfs创建文件夹，并将input文件放在hdfs文件夹下：123$ hadoop dfs -mkdir -p /wordcount2/input$ hadoop dfs -put /Users/liuqi/Desktop/input2.txt /wordcount2/input$ bin/hdfs dfs -ls /wordcount2/input spark-submit程序&emsp;&emsp;运行mapreduce程序：1$ bin/spark-submit --class WordCount --num-executors 2 --executor-memory 6g --executor-cores 4 /Users/liuqi/Desktop/wordcountspark.jar /wordcount2/output &emsp;&emsp;结果显示如下：&emsp;&emsp;注：如果中间有错，则删除对应文件重新进行操作：1$ bin/hdfs dfs -rm -r /wordcount2/input 查询结果&emsp;&emsp;结果保存在本地：1$ hadoop dfs -getmerge /wordcount2/output /Users/liuqi/Desktop/wordcount2/ 附加代码&emsp;&emsp;注：这里只是显示java代码，整个工程去我的CSDN博客进行下载。 http://download.csdn.net/detail/u012842255/9851234 WordCount.java:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106import scala.Tuple2;import org.apache.spark.SparkConf;import org.apache.spark.api.java.JavaPairRDD;import org.apache.spark.api.java.JavaRDD;import org.apache.spark.api.java.JavaSparkContext;import org.apache.spark.api.java.function.FlatMapFunction;import org.apache.spark.api.java.function.Function2;import org.apache.spark.api.java.function.PairFunction;import java.util.ArrayList;import java.util.Arrays;import java.util.Iterator;import java.util.List;import java.util.regex.Pattern;/** * * WordCount * @author 刘琦 */ public final class WordCount &#123; private static final Pattern SPACE = Pattern.compile(&quot; &quot;); public static void main(String[] args) throws Exception &#123; if (args.length &lt; 1) &#123; System.err.println(&quot;Usage: WordCount &lt;file&gt;&quot;); System.exit(1); &#125; SparkConf sparkConf = new SparkConf().setAppName(&quot;WordCount&quot;); JavaSparkContext ctx = new JavaSparkContext(sparkConf); JavaRDD&lt;String&gt; lines = ctx.textFile(&quot;hdfs://localhost:54310/wordcount2/input&quot;); JavaRDD&lt;String&gt; words = lines.flatMap(new FlatMapFunction&lt;String, String&gt;() &#123; public Iterator&lt;String&gt; call(String s) throws Exception &#123; // TODO Auto-generated method stub //大小写转化与去符号 String newStr = s.toLowerCase().replaceAll(&quot;[\\\\d\\\\pP\\\\p&#123;Punct&#125;]&quot;, &quot;&quot;);; String[] wordResult = SPACE.split(newStr); List&lt;String&gt; wordNewResult = new ArrayList&lt;String&gt;(); String[][] result = new String[wordResult.length][2]; for (int i = 0; i &lt; wordResult.length; i ++)&#123; result[i][0] = wordResult[i]; result[i][1] = &quot;0&quot;; &#125; //对每一行的单词进行处理 for(int i = 0; i &lt; wordResult.length ; i++)&#123; for(int j = 0; j &lt; wordResult.length; j++)&#123; if(i == j)&#123; continue; &#125;else if (result[i][1].equals(&quot;1&quot;))&#123; //这个词之前出现过了，这里只统计它之后还有没有相同的数据,后来发现不需要这一步了，相同的只计算一次就好 if(i&lt;j &amp;&amp; result[i][0].equals(result[j][0]))&#123; result[j][1] = &quot;1&quot;; //wordNewResult.add(&quot;(&quot; + result[i][0] + &quot; &quot; + result[j][0] + &quot;)&quot;); //word.set(&quot;(&quot; + result[i][0] + &quot; &quot; + result[j][0] + &quot;)&quot;);// output.collect(word, one); &#125; &#125;else&#123; //这个词之前没有出现过 if (!result[i][0].equals(result[j][0]))&#123; //普通操作 wordNewResult.add(&quot;(&quot; + result[i][0] + &quot; &quot; + result[j][0] + &quot;)&quot;);// word.set(&quot;(&quot; + result[i][0] + &quot; &quot; + result[j][0] + &quot;)&quot;); &#125;else&#123; //说明两个单词是一样的,并且这个单词之前没有统计过 result[j][1] = &quot;1&quot;; wordNewResult.add(&quot;(&quot; + result[i][0] + &quot; &quot; + result[j][0] + &quot;)&quot;);// word.set(&quot;(&quot; + result[i][0] + &quot; &quot; + result[j][0] + &quot;)&quot;); &#125; &#125; &#125; &#125; return wordNewResult.iterator(); &#125; &#125;); JavaPairRDD&lt;String, Integer&gt; ones = words.mapToPair(new PairFunction&lt;String, String, Integer&gt;() &#123; public Tuple2&lt;String, Integer&gt; call(String s) &#123; return new Tuple2&lt;String, Integer&gt;(s, 1); &#125; &#125;); JavaPairRDD&lt;String, Integer&gt; counts = ones.reduceByKey(new Function2&lt;Integer, Integer, Integer&gt;() &#123; public Integer call(Integer i1, Integer i2) &#123; return i1 + i2; &#125; &#125;); //创建Hdfs文件，打开Hdfs输出流 HdfsOperate.openHdfsFile(&quot;hdfs://localhost:54310/wordcount2/output&quot;); List&lt;Tuple2&lt;String, Integer&gt;&gt; output = counts.collect(); for (Tuple2&lt;?,?&gt; tuple : output) &#123; System.out.println(tuple._1() + &quot;: &quot; + tuple._2()); HdfsOperate.writeString(tuple._1() + &quot;: &quot; + tuple._2()); &#125; ctx.stop(); //关闭Hdfs输出流 HdfsOperate.closeHdfsFile(); &#125; &#125; HdfsOperate.java：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;import org.apache.hadoop.hdfs.web.resources.ExceptionHandler;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.*;import java.net.URI;/** * 使用Hadoop的FileSystem把数据写入到HDFS */public class HdfsOperate implements Serializable&#123; private static Logger logger = LoggerFactory.getLogger(HdfsOperate.class); private static Configuration conf = new Configuration(); private static BufferedWriter writer = null; //在hdfs的目标位置新建一个文件，得到一个输出流 public static void openHdfsFile(String path) throws Exception &#123; FileSystem fs = FileSystem.get(URI.create(path),conf); writer = new BufferedWriter(new OutputStreamWriter(fs.create(new Path(path)))); if(null!=writer)&#123; logger.info(&quot;[HdfsOperate]&gt;&gt; initialize writer succeed!&quot;); &#125; &#125; //往hdfs文件中写入数据 public static void writeString(String line) &#123; try &#123; writer.write(line + &quot;\\n&quot;); &#125;catch(Exception e)&#123; logger.error(&quot;[HdfsOperate]&gt;&gt; writer a line error:&quot; , e); &#125; &#125; //关闭hdfs输出流 public static void closeHdfsFile() &#123; try &#123; if (null != writer) &#123; writer.close(); logger.info(&quot;[HdfsOperate]&gt;&gt; closeHdfsFile close writer succeed!&quot;); &#125; else&#123; logger.error(&quot;[HdfsOperate]&gt;&gt; closeHdfsFile writer is null&quot;); &#125; &#125;catch(Exception e)&#123; logger.error(&quot;[HdfsOperate]&gt;&gt; closeHdfsFile close hdfs error:&quot; + e); &#125; &#125;&#125;","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"Java","slug":"Java","permalink":"http://blog.killyliu.com/tags/Java/"},{"name":"Wordcount","slug":"Wordcount","permalink":"http://blog.killyliu.com/tags/Wordcount/"}]},{"title":"Java实现Hadoop词配对Wordcount计数","date":"2017-05-20T09:01:00.000Z","path":"2017/05/20/Java实现Hadoop下词配对Wordcount计数/","text":"需求&emsp;&emsp;使用Hadop实现 Mapper/Reducer，对一个文档中的每一行的单词进行词配对计数，要求去标点符号，将大写符号统一转化成为小写单词。 &emsp;&emsp;举例说明，最初的文档为： “a a, A ba b c 则处理后的结果为： (a a) 2(a b) 2(a c) 1(b a) 4(b c) 1(c a) 1(c b) 1 实现过程开启hadoop进入Hadoop所在的文件夹并执行启动语句：1$ sbin/start-all.sh jar包处理将编码程序打包成jar包进行处理 HDFS文件设置使用hdfs创建文件夹，并将input文件放在hdfs文件夹下：123$ bin/hdfs dfs -mkdir -p /wordcount1/input$ bin/hdfs dfs -put /Users/liuqi/Desktop/input.txt /wordcount1/input$ bin/hdfs dfs -ls /wordcount1/input mapreduce程序运行mapreduce程序：1$ bin/hadoop jar /Users/liuqi/Desktop/wordcount.jar WordCount /wordcount1/input /wordcount1/output 注：如果中间有错，则删除对应文件重新进行操作：1$ bin/hdfs dfs -rm -r /wordcount1/input 查询结果查看计数的结果：12$ bin/hdfs dfs -ls /wordcount1/output$ bin/hdfs dfs -cat /wordcount1/output/part-00000 将结果保存在本地：1$ bin/hdfs dfs -getmerge /wordcount1/output /Users/liuqi/Desktop/wordcount1/ 附加代码注：这里只是显示java代码，整个工程去我的CSDN博客进行下载： http://download.csdn.net/detail/u012842255/9851124 WordCount.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135import java.io.IOException; import java.util.Iterator; import java.util.StringTokenizer; import org.apache.hadoop.fs.Path; import org.apache.hadoop.io.IntWritable; import org.apache.hadoop.io.LongWritable; import org.apache.hadoop.io.Text; import org.apache.hadoop.mapred.FileInputFormat; import org.apache.hadoop.mapred.FileOutputFormat; import org.apache.hadoop.mapred.JobClient; import org.apache.hadoop.mapred.JobConf; import org.apache.hadoop.mapred.MapReduceBase; import org.apache.hadoop.mapred.Mapper; import org.apache.hadoop.mapred.OutputCollector; import org.apache.hadoop.mapred.Reducer; import org.apache.hadoop.mapred.Reporter; import org.apache.hadoop.mapred.TextInputFormat; import org.apache.hadoop.mapred.TextOutputFormat; /** * * WordCount * @author 刘琦 */ public class WordCount &#123; /** * MapReduceBase类:实现了Mapper和Reducer接口的基类（其中的方法只是实现接口，而未作任何事情） * Mapper接口： * WritableComparable接口：实现WritableComparable的类可以相互比较。所有被用作key的类应该实现此接口。 * Reporter 则可用于报告整个应用的运行进度，本例中未使用。 * */ public static class Map extends MapReduceBase implements Mapper&lt;LongWritable, Text, Text, IntWritable&gt; &#123; /** * LongWritable, IntWritable, Text 均是 Hadoop 中实现的用于封装 Java 数据类型的类，这些类实现了WritableComparable接口， * 都能够被串行化从而便于在分布式环境中进行数据交换，你可以将它们分别视为long,int,String 的替代品。 */ private final static IntWritable one = new IntWritable(1); private Text word = new Text(); /** * Mapper接口中的map方法： * void map(K1 key, V1 value, OutputCollector&lt;K2,V2&gt; output, Reporter reporter) * 映射一个单个的输入k/v对到一个中间的k/v对 * 输出对不需要和输入对是相同的类型，输入对可以映射到0个或多个输出对。 * OutputCollector接口：收集Mapper和Reducer输出的&lt;k,v&gt;对。 * OutputCollector接口的collect(k, v)方法:增加一个(k,v)对到output */ public void map(LongWritable key, Text value, OutputCollector&lt;Text, IntWritable&gt; output, Reporter reporter) throws IOException &#123; //变成小写单词，并且去各种符号 String line = value.toString().toLowerCase().replaceAll(&quot;[\\\\d\\\\pP\\\\p&#123;Punct&#125;]&quot;, &quot;&quot;); StringTokenizer tokenizer = new StringTokenizer(line); StringTokenizer tokenizer2 = new StringTokenizer(line); String[][] result = new String[tokenizer.countTokens()][2]; int k = 0; while (tokenizer.hasMoreTokens()) &#123; result[k][0] = tokenizer.nextToken(); result[k][1] = &quot;0&quot;; k++; &#125; //对每一行的单词进行处理 for(int i = 0; i &lt; tokenizer2.countTokens() ; i++)&#123; for(int j = 0; j &lt; tokenizer2.countTokens() ; j++)&#123; if(i == j)&#123; continue; &#125;else if (result[i][1].equals(&quot;1&quot;))&#123; //这个词之前出现过了，这里只统计它之后还有没有相同的数据,后来发现不需要这一步了，相同的只计算一次就好 if(i&lt;j &amp;&amp; result[i][0].equals(result[j][0]))&#123; result[j][1] = &quot;1&quot;; word.set(&quot;(&quot; + result[i][0] + &quot; &quot; + result[j][0] + &quot;)&quot;);// output.collect(word, one); &#125; &#125;else&#123; //这个词之前没有出现过 if (!result[i][0].equals(result[j][0]))&#123; //普通操作 word.set(&quot;(&quot; + result[i][0] + &quot; &quot; + result[j][0] + &quot;)&quot;); output.collect(word, one); &#125;else&#123; //说明两个单词是一样的,并且这个单词之前没有统计过 result[j][1] = &quot;1&quot;; word.set(&quot;(&quot; + result[i][0] + &quot; &quot; + result[j][0] + &quot;)&quot;); output.collect(word, one); &#125; &#125; &#125; &#125; &#125; &#125; public static class Reduce extends MapReduceBase implements Reducer&lt;Text, IntWritable, Text, IntWritable&gt; &#123; public void reduce(Text key, Iterator&lt;IntWritable&gt; values, OutputCollector&lt;Text, IntWritable&gt; output, Reporter reporter) throws IOException &#123; int sum = 0; while (values.hasNext()) &#123; sum += values.next().get(); &#125; output.collect(key, new IntWritable(sum)); &#125; &#125; public static void main(String[] args) throws Exception &#123; /** * JobConf：map/reduce的job配置类，向hadoop框架描述map-reduce执行的工作 * 构造方法：JobConf()、JobConf(Class exampleClass)、JobConf(Configuration conf)等 */ JobConf conf = new JobConf(WordCount.class); conf.setJobName(&quot;wordcount&quot;); //设置一个用户定义的job名称 conf.setOutputKeyClass(Text.class); //为job的输出数据设置Key类 conf.setOutputValueClass(IntWritable.class); //为job输出设置value类 conf.setMapperClass(Map.class); //为job设置Mapper类 conf.setCombinerClass(Reduce.class); //为job设置Combiner类 conf.setReducerClass(Reduce.class); //为job设置Reduce类 conf.setInputFormat(TextInputFormat.class); //为map-reduce任务设置InputFormat实现类 conf.setOutputFormat(TextOutputFormat.class); //为map-reduce任务设置OutputFormat实现类 /** * InputFormat描述map-reduce中对job的输入定义 * setInputPaths():为map-reduce job设置路径数组作为输入列表 * setInputPath()：为map-reduce job设置路径数组作为输出列表 */ FileInputFormat.setInputPaths(conf, new Path(args[0])); FileOutputFormat.setOutputPath(conf, new Path(args[1])); JobClient.runJob(conf); //运行一个job &#125; &#125;","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"Java","slug":"Java","permalink":"http://blog.killyliu.com/tags/Java/"},{"name":"Wordcount","slug":"Wordcount","permalink":"http://blog.killyliu.com/tags/Wordcount/"}]},{"title":"Ubuntu虚拟机实现两结点SSH免密码通信","date":"2017-05-11T07:55:22.000Z","path":"2017/05/11/Ubuntu虚拟机实现两结点SSH免密码通信/","text":"实现功能： 创建两台Ubuntu VM 16.04 虚拟机，并更改hostname 做结点的hostname到IP的映射 并实现SSH通信 在虚拟机上部署服务，查看应用效果 准备工作 &emsp;&ensp;这里创建了两台ubuntu VM 16.04 虚拟机进行操作。 &emsp;&ensp;Server1: 192.168.113.143 &emsp;&ensp;Server2: 192.168.113.144 设置主机名hostname &emsp;&ensp;编辑hostname文件，设置主机名。这里为了识别方便，给两个服务器结点分别设为server1, server2。1$ sudo gedit /etc/hostname &emsp;&ensp;重启虚拟机，便可以看到服务器的主机名为server1，server2。 设置IP主机映射 &emsp;&ensp;编辑hosts文件并设置hosts与IP的映射关系：1$ sudo gedit /etc/hosts 在文件中添加信息：12192.168.113.143 server1192.168.113.144 server2 SSH配置设置SSH keygen &emsp;&ensp;为每个服务器设置keygen：1$ ssh-keygen –t rsa 拷贝SSH KEY &emsp;&ensp;将公秘钥拷贝给对方服务器：1$ ssh-copy-id server2 注：如果这里我们之前做过拷贝，则需要用-f：1$ ssh-copy-id –f server2 使用SSH登录到对方服务器 &emsp;&ensp;这里举例用server2登录到server1:1$ ssh server1 Tomcat配置jdk配置 &emsp;&ensp;使用远程拷贝的方式将电脑本地的jdk包传到远程服务器上，并解压做相关配置。 &emsp;&ensp;编辑profile文件，做JAVA_HOME配置：123456789$ vim /etc/profileJAVA_HOME=/usr/local/jdk1.8.0_131JRE_HOME=$JAVA_HOME/jrePATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binCLASSPATH=:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libexport JAVA_HOME JRE_HOME PATH CLASSPATH$ source /etc/profile &emsp;&ensp;使用java -version查看现在的jdk信息：1$ java -version Tomcat配置 &emsp;&ensp;下载并解压Tomcat。 &emsp;&ensp;进入Tomcat的安装地址并启动Tomcat1$ bin/startup.sh war包运行 &emsp;&ensp;这里我将自己的项目打包成war包，并且放在tomcat下的webapps 文件夹下： &emsp;&ensp;重新运行tomcat，即可看到自己的项目:1$ bin/startup.sh","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"SSH","slug":"SSH","permalink":"http://blog.killyliu.com/tags/SSH/"},{"name":"Ubuntu虚拟机","slug":"Ubuntu虚拟机","permalink":"http://blog.killyliu.com/tags/Ubuntu虚拟机/"}]},{"title":"阿里云Ubuntu服务器实现两结点SSH免密码通信","date":"2017-05-10T06:55:00.000Z","path":"2017/05/10/阿里云Ubuntu服务器实现两结点SSH免密码通信/","text":"实现功能： 阿里云上创建两个结点，更改hostname 做结点的hostname到IP的映射 并实现SSH通信 在虚拟机上部署服务，查看应用效果 准备工作 &emsp;&ensp;这里在阿里云上创建了两个实例，这里我的两个服务器分别是：使用学生套餐9.9租用了一个服务器，使用按时按流量计费的方式租用了另一台服务器。 &emsp;&ensp;都创建为：ubuntu VM 16.04 &emsp;&ensp;Server1: 47.94.95.40 / 172.17.78.48 &emsp;&ensp;Server2: 47.52.107.97 / 172.31.162.43 设置主机名hostname &emsp;&ensp;编辑hostname文件，设置主机名。这里为了识别方便，给两个服务器结点分别设为server1, server2。1$ vim /etc/hostname &emsp;&ensp;重启虚拟机，便可以看到服务器的主机名为server1，server2。1$ shutdown –r now 设置IP主机映射 &emsp;&ensp;编辑hosts文件并设置hosts与IP的映射关系：1vim /etc/hosts 在文件中添加信息：1247.94.95.40 server147.52.107.97 server2 SSH配置设置SSH keygen &emsp;&ensp;首先，要确认服务器已开启密码权利(password authentication)1$ vim /etc/ssh/sshd_config &emsp;&ensp;确认passwordAuthentication 是yes，然后重新加载。1$ /etc/init.d/sshd reload &emsp;&ensp;然后为每个服务器设置keygen：1$ ssh-keygen 拷贝SSH KEY &emsp;&ensp;将公秘钥拷贝给对方服务器：1$ ssh-copy-id root@server2 使用SSH登录到对方服务器 &emsp;&ensp;这里举例用server2登录到server1:1$ ssh server1 Tomcat配置jdk配置 &emsp;&ensp;使用远程拷贝的方式将电脑本地的jdk包传到远程服务器上，并解压做相关配置。1$ scp /Users/liuqi/Downloads/jdk-8u131-linux-x64.tar root@47.94.95.40:/usr/local &emsp;&ensp;编辑profile文件，做JAVA_HOME配置：123456789$ vim /etc/profileJAVA_HOME=/usr/local/jdk1.8.0_131JRE_HOME=$JAVA_HOME/jrePATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binCLASSPATH=:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libexport JAVA_HOME JRE_HOME PATH CLASSPATH$ source /etc/profile &emsp;&ensp;使用java -version查看现在的jdk信息：1$ java -version Tomcat配置 &emsp;&ensp;下载并解压Tomcat:123$ wget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-7/v7.0.77/bin/apache-tomcat-7.0.77.tar.gz$ mv apache-tomcat-7.0.77.tar.gz /usr/local$ tar -xvzf /usr/local/apache-tomcat-7.0.77.tar.gz &emsp;&ensp;进入Tomcat的安装地址并启动Tomcat1$ bin/startup.sh war包运行 &emsp;&ensp;这里我将自己的项目打包成war包，并且放在tomcat下的webapps 文件夹下，重新运行tomcat，即可看到自己的项目：","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"SSH","slug":"SSH","permalink":"http://blog.killyliu.com/tags/SSH/"},{"name":"阿里云服务器","slug":"阿里云服务器","permalink":"http://blog.killyliu.com/tags/阿里云服务器/"}]},{"title":"挖掘模型(3)--Mahout建基于用户的推荐模型","date":"2017-05-03T15:52:31.000Z","path":"2017/05/03/挖掘模型-3-Mahout建基于用户的推荐模型/","text":"这里我们用mahout建简单的基于用户的推荐。 前提条件 已经安装好Eclipse环境 下载完成mahout配置包 工程环境打开eclipse，新建一个maven项目 使用默认工作环境 选择快速开始 设置基本信息：Group ID：com.recommenderExampleArtifact ID：MahoutRecommender默认版本：0.0.1-SNAPSHOT包：com.recommenderExample.MahoutRecommender 创建完成 项目右键-&gt;新建-&gt;文件夹 分别创建：data：用于存放数据集lib：用于引入其他数据库(主要为mahout数据库) 将下载的mahout压缩包解压，复制jar包到Lib文件夹下 右键点击项目-&gt;配置环境 点击添加jar包，添加刚引入的包 数据集Mahout推荐算法是希望将用户与项之间的关系作为输入进行计算，这里采用最简单的txt文本方式保存数据。我们用”dataset.csv”来保存数据，分别代表userID,itemID,value。数据集： 1,10,1.01,11,2.01,12,5.01,13,5.01,14,5.01,15,4.01,16,5.01,17,1.01,18,5.02,10,1.02,11,2.02,15,5.02,16,4.52,17,1.02,18,5.03,11,2.53,12,4.53,13,4.03,14,3.03,15,3.53,16,4.53,17,4.03,18,5.04,10,5.04,11,5.04,12,5.04,13,0.04,14,2.04,15,3.04,16,1.04,17,4.04,18,1.0 点击data文件夹(右键)-&gt;新建-&gt;文件，命名 dataset.csv 将数据文件拖到面板中，复制上面的数据 创建基于用户的推荐在App类中创建数据模型：1DataModel model = new FileDataModel(new File(&quot;/path/to/dataset.csv&quot;)); 我们根据其他相似品味用户的信息来推断特定用户的推荐，用相互作用关系来推断彼此之间的联系：1UserSimilarity similarity = new PearsonCorrelationSimilarity(model); 定义相似的用户，超过0.1的可能性则认为是相似的：1UserNeighborhood neighborhood = new ThresholdUserNeighborhood(0.1, similarity, model); 根据数据模型、相似信息、相似用户来创建推荐：1UserBasedRecommender recommender = new GenericUserBasedRecommender(model, neighborhood, similarity); 显示推荐信息：1234List recommendations = recommender.recommend(2, 3);for (RecommendedItem recommendation : recommendations) &#123; System.out.println(recommendation);&#125; 运行：可以看出：用户2 中 item12的阅读值为4.8328104，item13的阅读值为4.6656213，item13的阅读值为4.331242。用户2最可能购买的是item12，13，14。 对于警告：可以添加slf4j-nop-1.7.7.jar解决。 评估我们区分数据集为两种：90% trainingset10% testset创建新类：EvaluateRecommender 创建实现RecommenderBuilder接口的类MyRecommenderBuilder:12345678class myRecommenerBuilder implements RecommenderBuilder&#123; public Recommender buildRecommender(DataModel dataModel) throws TasteException &#123; UserSimilarity similarity = new PearsonCorrelationSimilarity(dataModel); UserNeighborhood neighborhood = new ThresholdUserNeighborhood(0.1, similarity, dataModel); return new GenericUserBasedRecommender(dataModel, neighborhood, similarity); &#125; &#125; 测试代码：12345DataModel model = new FileDataModel(new File(&quot;data/dataset.csv&quot;)); RecommenderEvaluator evaluator = new AverageAbsoluteDifferenceRecommenderEvaluator(); RecommenderBuilder builder = new myRecommenderBuilder(); double result = evaluator.evaluate(builder, null, model, 0.9, 1.0); System.out.println(result); 进行测试(每次运行结果不同，值越低越好)：","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"http://blog.killyliu.com/tags/数据挖掘/"}]},{"title":"挖掘模型(2)--Oracle建挖掘模型","date":"2017-05-02T15:50:41.000Z","path":"2017/05/02/挖掘模型-2-Oracle建挖掘模型/","text":"场景：寻找可能购买保险的潜在客户。 前提条件 下载并安装完成Oracle 11g (R2)企业版 下载Oracle管理工具Oracle SQL Developer3.0或者更新版(windows下使用) 系统用户(SYS)已经建好：密码，数据库端口号，数据库服务ID 数据挖掘账号创建与连接创建数据挖掘用户账号双击 sqldeveloper.exe 打开管理工具 点击连接(右键)-&gt;新建连接 填写信息： 连接名：admin用户名：sys口令：自己设置的Oracle数据库密码连接类型：基本角色：SYSDBA主机名：localhost端口号：自己设置的端口号，默认1521SID：自己设置的服务ID 点击测试成功后，点击连接。 创建数据挖掘的账号：点开admin账号，点击其他用户(右键)-&gt;创建用户 填写信息： 用户名：dduser新口令：用户密码确认新口令：用户密码默认表空间：USERS临时表空间：TEMP 点击授予的权限-&gt;设置连接 点击限额-&gt;用户USER设为无限制，点击应用。 为数据挖掘账户创建连接点击连接(右键)-&gt;新建连接 填写信息： 连接名：dduser用户名：dduser口令：自己设置的密码连接类型：基本角色：默认主机名：localhost端口号：自己设置的端口号，默认1521SID：自己设置的服务ID 点击连接： 下载数据挖掘知识库点击查看(V)-&gt;数据挖掘-&gt;数据挖掘连接 可以看到已经跳转到数据挖掘页面 点击连接(右键)-&gt;添加连接 建立与admin和dduser的连接 双击dduser，对于权限提醒，选择配置权限(是) 出现连接信息，输入密码，点击确定。 点击开始按钮，运行安装任务 创建数据挖掘项目在数据挖掘一栏，点击dduser(右键)-&gt;新建项目 填写项目名 ：ABC Insurance 点击确定，结果如下： 构建数据挖掘工作流这里，我们用挖掘模型预测已有客户中可能会购买保险的人。 创建工作流并添加数据源点击ABCInsurance(右键)-&gt;新建工作流 填写工作流名称：Targeting Best Customers 会出现工作流信息，右面有组件信息 添加数据源结点，拖到工作流页面中。 定义数据源：选择可用表：CUST_INSUR_LTV_SAMPLE，下一步选择列：这里选择所有列，点击完成。 检验元数据添加浏览数据结点注：右上角有感叹号说明还没有完成整个步骤 右键点击数据源结点(INSUR_CUST_LTV_SAMPLE)，选择连接，点击浏览数据 双击 浏览数据结点，分组方式选择BUY_INSURANCE，点击确定 点击浏览数据(右键)-&gt;运行 运行完成的效果如下： 右键浏览数据，选择查看数据： 显示浏览数据 注：之前GROUP BY可以选择不同的类型：Histogram, Distinct Values, Mode, Average, Min and Max value, Standard Deviation, Variance, Skewness, and Kurtosis，可以根据需要做不同的分析。 创建分类模型选择分类模型： 建立从数据元到分类构建的连接 目标：BUY_INSURANCE案例ID：CUSTOMER_ID双击CLAS_SVM_31_3,，进入高级模式设置，核函数选择线性。 构建模型(“training” a model)点击类构建(右键)-&gt;转到属性 在测试一栏中将拆分供测试设置为50 运行类构建 在属性中可以看到所有模型构建成功 比较模型点击类构建(右键)-&gt;比较测试结果 四个模型的基本比较： 选择提升按钮查看模型： 选择性能矩阵比较(选择具体的模型可以查看比较)： 选择和测试具体模型这里我们以决策树来举例。点击类构建(右键)-&gt;查看模型-&gt;CLAS_DT_1_3 显示节点具体信息(比例最好选择100%) 点击节点可以查看到具体信息： 应用模型添加数据源选择表：CUST_INSUR_LTV_SAMPLE重命名：CUST_INSUR_LTV_APPLY 在评估与应用中，选择 应用重命名：Apply Model 在类构建与应用(Apply Model)之间添加链接 在表(CUST_INSUR_LTV_APPLY) 与应用(Apply Model)之间添加链接 这里做简单的输出调整：点击应用(右键)-&gt;编辑 设置预测节点输出：这里可以看到已有的预测列 我们需要再添加一列CUSTOMER_ID：点击 附加输出-&gt;添加按钮-&gt;选择CUSTOMER_ID 点击确定之后，运行应用模型： 最后，每个图标的右上角都会有一个小勾，表明运行成功 将预测结果保存在数据库表中(可选)将创建表或试图 拖到界面中 建立从应用模型(Apply Model)到输出节点(OUTPUT)的连接 点击 输出 节点-&gt;编辑 设置表名：DT_PREDICTIONS 确定后点击表节点（DT_PREDICTIONS）右键运行 运行成功后，右键表节点（DT_PREDICTIONS）-&gt;查看视图 点击排序，选择CLAS_DT_1_3_PROB降序形式 点击应用排序并查看结果","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"http://blog.killyliu.com/tags/数据挖掘/"}]},{"title":"挖掘模型(1)--SqlServer2012建挖掘模型","date":"2017-05-01T15:46:13.000Z","path":"2017/05/01/挖掘模型-1-SqlServer2012建挖掘模型/","text":"&emsp;&emsp;Microsoft SQL Server提供了集成的数据挖掘建模分析环境，这里我们用SQL Server官网提供的数据创建模型并用于分析顾客购车行为，从而预测潜在购车客户。 前提条件安装：Microsoft SQL Server 2012 （注：最好英文版，中文版有些地方可能会出错）安装：多维模式下的Microsoft SQL Server 分析服务数据库：采用官网的样例数据库 http://go.microsoft.com/fwlink/?LinkId=88417 准备分析服务数据库&emsp;&emsp;使用SQL Server建立商业智能应用程序（ business intelligence application）进行建模分析。用数据工具(SQL Server Data Tools (SSDT))建立分析服务项目（SQL Server Analysis Services project），之后建立一或多个数据源（data sources），然后定义元数据视图（data source view）。 创建分析服务项目(Analysis Services Project)打开SQL Server数据工具(SQL Server Data Tools (SSDT)) 注意：要确认是商业智能项目模式（Business Intelligence Projects）。更改步骤：工具-&gt;导入和导出设置。一直到下一步，可以看到环境为 商业智能集合。 点击 文件-&gt;新建-&gt;项目 选择分析服务多维和数据挖掘项目（Analysis Services Multidimensional and Data Mining Project），项目起名为CustomerDataMining。 确认项目部署的服务名：点击项目(右键)-&gt;属性-&gt;部署-&gt;服务器为localhost。 创建数据源(Data Source)数据源文件夹(右键)-&gt;新建数据源 跳过欢迎页进行下一步-&gt;新建 点击服务器名，选择自己的服务器(若为空则手动输入localhost)-&gt;刷新-&gt;选择数据库(这里我们从外部导入之下下载的样例数据库)-&gt;确定 选择服务账户 数据源起名Adventure Works DW 2012，点击完成。 创建数据源视图(Data Source View)通过数据源视图，我们可以选择项目所需要的数据，建立表之间的关系，在不修改原来的数据的情况下修改数据的结构。 点击数据源视图(右键)-&gt;新建数据源视图 选择已有数据源-&gt;下一步 选择需要的表或视图，这里我们选择：ProspectiveBuyer (dbo) – 可能购车者信息vTargetMail (dbo) – 曾经购车者信息 点击下一步，设置视图名 Targeted Mailing，点击完成。 创建目标邮件结构创建目标邮件挖掘模型结构(Targeted Mailing Mining Model Structure)点击挖掘结构(右键)-&gt;新建挖掘结构 下一步-&gt;从已有的数据仓库选择-&gt;数据挖掘结构，我们选择决策树 选择数据源： 选择模型信息，我们最少需要一个预测列，一个输入列和一个关键值列。 预测列：• BikeBuyer关键值：• CustomerKey输入列：• Age• CommuteDistance• EnglishEducation• EnglishOccupation• Gender• GeographyKey• HouseOwnerFlag• MaritalStatus• NumberCarsOwned• NumberChildrenAtHome • Region• TotalChildren• YearlyIncome其他分析列：• AddressLine1• AddressLine2• DateFirstPurchase • EmailAddress• FirstName• LastName 确认数据类型，内容类型(Content and Data Type)点击检测按钮，对信息类型进行基本检测，点击完成。注：这里GeographyKey 是文本，不然可能会有标识符等不识别错误。 确认测试数据集结构(Testing Data Set for the Structure)这里设置测试比例为30%，测试集中最大数量为1000。 挖掘数据结构名：Targeted Mailing挖掘模型名：TM_Decision_Tree选择允许通过，点击完成。 添加·处理模型点击挖掘模型页面，我们可以看到之前建立的决策树模型，这里我们再建立两个模型，模型处理这里省略了。 聚类分析挖掘模型点击结构(右键)-&gt;新建挖掘模型 模型名 TM_Clustering，选择聚类分析算法。 朴素贝叶斯挖掘模型点击结构(右键)-&gt;新建挖掘模型模型名 TM_NaiveBayes，选择朴素贝叶斯算法。 模型探索由于挖掘模型的结果是复杂的，因而我们采用图形等简易的方式进行展示更加直观。 决策树模型点击查看挖掘模型视图，点击部署，运行。运行报错 原因是没有设置数据库的用户名。打开管理工具，新建登录，登录名为报错内容的ODBC连接错误用户名。 重新部署。 显示等级默认为3，这里改为4。背景值改为1，（这里1代表曾经购买过车，0代表未曾购买过车） 点击结点(右键) -&gt;钻取-&gt;仅模型/模型和结构 聚类分析模型挖掘模型部分选择聚类分析模型，选择Microsoft集群视图( Microsoft Cluster Viewer)，阴影变量处选购车者，状态选1。 点击节点(右键)可以进行重命名，这里将浅色节点命名Bike Buyers Low，深色节点为Bike Buyers High。 点击集群配置文件，设置直方图为5，查看不同因素的影响。 点击集群识别标签，设置集群1为Bike Buyers High，集群2为Bike Buyers Low。 朴素贝叶斯模型选择朴素贝叶斯模型，同样进行相关分析。 测试模型用梯度图测试准确性选择输入数据集，模型，预测列，值。 点击梯度图： 测试过滤模型之前我们已经对比得到决策树的准确性相对最高，这里用于测不同性别人购车对比。在挖掘模型页面新建两个模型：TM_Decision_Tree_Male，TM_Decision_Tree_Female。 点击决策树右键，添加模型筛选器 将新建的两个模型点右键进行处理 对两个模型都点击挖掘模型视图，设置背景为1，等级为3。 设置精确度 查看不同性别对比 进行预测创建预测在挖掘模型中，点击选择模型，选择决策树模型。 在测试表中选择 ProspectiveBuyer (dbo)更改信息 在解决方案资源管理器中，数据源视图右键，点击视图设计器 右键表ProspectiveBuyer，新建命名计算，输入信息。列名 calcAge，描述 Calculate age based on birthdate，表达式 DATEDIFF(YYYY,[BirthDate],getdate()) 在挖掘模型中，重新修改连接，年龄选择ProspectiveBuyer.calcAge。 source选择Prediction Function，field选择PredictProbability，alias选择Probability of result，将Bike Buyer拖到Criteria/Argument。 点击查询结果 钻取数据视图在挖掘模型视图中，选择结点（例age &gt;= 43 and &lt; 50）右键钻取，模型和结构列，查看钻取结果。","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"http://blog.killyliu.com/tags/数据挖掘/"}]},{"title":"人脸识别(4)--Python3.6+dlib19.4识别实例","date":"2017-04-20T05:29:14.000Z","path":"2017/04/20/人脸识别-4-Python3-6-dlib19-4识别实例/","text":"前提条件：确保python+dlib环境已经搭建成功，(搭建步骤可以参考上一篇博客)。 生成方形框识别人脸官网代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#!/usr/bin/python# The contents of this file are in the public domain. See LICENSE_FOR_EXAMPLE_PROGRAMS.txt## This example program shows how to find frontal human faces in an image. In# particular, it shows how you can take a list of images from the command# line and display each on the screen with red boxes overlaid on each human# face.## The examples/faces folder contains some jpg images of people. You can run# this program on them and see the detections by executing the# following command:# ./face_detector.py ../examples/faces/*.jpg## This face detector is made using the now classic Histogram of Oriented# Gradients (HOG) feature combined with a linear classifier, an image# pyramid, and sliding window detection scheme. This type of object detector# is fairly general and capable of detecting many types of semi-rigid objects# in addition to human faces. Therefore, if you are interested in making# your own object detectors then read the train_object_detector.py example# program. ### COMPILING THE DLIB PYTHON INTERFACE# Dlib comes with a compiled python interface for python 2.7 on MS Windows. If# you are using another python version or operating system then you need to# compile the dlib python interface before you can use this file. To do this,# run compile_dlib_python_module.bat. This should work on any operating# system so long as you have CMake and boost-python installed.# On Ubuntu, this can be done easily by running the command:# sudo apt-get install libboost-python-dev cmake## Also note that this example requires scikit-image which can be installed# via the command:# pip install -U scikit-image# Or downloaded from http://scikit-image.org/download.html. import sysimport dlibfrom skimage import iodetector = dlib.get_frontal_face_detector()win = dlib.image_window()print(&quot;a&quot;);for f in sys.argv[1:]: print(&quot;a&quot;); print(&quot;Processing file: &#123;&#125;&quot;.format(f)) img = io.imread(f) # The 1 in the second argument indicates that we should upsample the image # 1 time. This will make everything bigger and allow us to detect more # faces. dets = detector(img, 1) print(&quot;Number of faces detected: &#123;&#125;&quot;.format(len(dets))) for i, d in enumerate(dets): print(&quot;Detection &#123;&#125;: Left: &#123;&#125; Top: &#123;&#125; Right: &#123;&#125; Bottom: &#123;&#125;&quot; .format(i, d.left(), d.top(), d.right(), d.bottom())) win.clear_overlay() win.set_image(img) win.add_overlay(dets) dlib.hit_enter_to_continue()# Finally, if you really want to you can ask the detector to tell you the score# for each detection. The score is bigger for more confident detections.# Also, the idx tells you which of the face sub-detectors matched. This can be# used to broadly identify faces in different orientations.if (len(sys.argv[1:]) &gt; 0): img = io.imread(sys.argv[1]) dets, scores, idx = detector.run(img, 1) for i, d in enumerate(dets): print(&quot;Detection &#123;&#125;, score: &#123;&#125;, face_type:&#123;&#125;&quot; .format(d, scores[i], idx[i])) 简略总结：1234567891011121314151617181920212223242526272829303132333435# -*- coding: utf-8 -*-import sysimport dlibfrom skimage import io#使用dlib自带的frontal_face_detector作为我们的特征提取器detector = dlib.get_frontal_face_detector()#使用dlib提供的图片窗口win = dlib.image_window()#sys.argv[]是用来获取命令行参数的，sys.argv[0]表示代码本身文件路径，所以参数从1开始向后依次获取图片路径for f in sys.argv[1:]: #输出目前处理的图片地址 print(&quot;Processing file: &#123;&#125;&quot;.format(f)) #使用skimage的io读取图片 img = io.imread(f) #使用detector进行人脸检测 dets为返回的结果 dets = detector(img, 1) #dets的元素个数即为脸的个数 print(&quot;Number of faces detected: &#123;&#125;&quot;.format(len(dets))) #使用enumerate 函数遍历序列中的元素以及它们的下标 #下标i即为人脸序号 #left：人脸左边距离图片左边界的距离 ；right：人脸右边距离图片左边界的距离 #top：人脸上边距离图片上边界的距离 ；bottom：人脸下边距离图片上边界的距离 for i, d in enumerate(dets):print(&quot;dets&#123;&#125;&quot;.format(d)) print(&quot;Detection &#123;&#125;: Left: &#123;&#125; Top: &#123;&#125; Right: &#123;&#125; Bottom: &#123;&#125;&quot; .format( i, d.left(), d.top(), d.right(), d.bottom())) #也可以获取比较全面的信息，如获取人脸与detector的匹配程度 dets, scores, idx = detector.run(img, 1) for i, d in enumerate(dets): print(&quot;Detection &#123;&#125;, dets&#123;&#125;,score: &#123;&#125;, face_type:&#123;&#125;&quot;.format( i, d, scores[i], idx[i])) #绘制图片(dlib的ui库可以直接绘制dets) win.set_image(img) win.add_overlay(dets) #等待点击 dlib.hit_enter_to_continue() 实例效果： 关键线识别人脸官方代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#!/usr/bin/python# The contents of this file are in the public domain. See LICENSE_FOR_EXAMPLE_PROGRAMS.txt## This example program shows how to find frontal human faces in an image and# estimate their pose. The pose takes the form of 68 landmarks. These are# points on the face such as the corners of the mouth, along the eyebrows, on# the eyes, and so forth.## This face detector is made using the classic Histogram of Oriented# Gradients (HOG) feature combined with a linear classifier, an image pyramid,# and sliding window detection scheme. The pose estimator was created by# using dlib&apos;s implementation of the paper:# One Millisecond Face Alignment with an Ensemble of Regression Trees by# Vahid Kazemi and Josephine Sullivan, CVPR 2014# and was trained on the iBUG 300-W face landmark dataset.## Also, note that you can train your own models using dlib&apos;s machine learning# tools. See train_shape_predictor.py to see an example.## You can get the shape_predictor_68_face_landmarks.dat file from:# http://sourceforge.net/projects/dclib/files/dlib/v18.10/shape_predictor_68_face_landmarks.dat.bz2 ## COMPILING THE DLIB PYTHON INTERFACE# Dlib comes with a compiled python interface for python 2.7 on MS Windows. If# you are using another python version or operating system then you need to# compile the dlib python interface before you can use this file. To do this,# run compile_dlib_python_module.bat. This should work on any operating# system so long as you have CMake and boost-python installed.# On Ubuntu, this can be done easily by running the command:# sudo apt-get install libboost-python-dev cmake## Also note that this example requires scikit-image which can be installed# via the command:# pip install -U scikit-image# Or downloaded from http://scikit-image.org/download.html. import sysimport osimport dlibimport globfrom skimage import ioif len(sys.argv) != 3: print(&quot;Give the path to the trained shape predictor model as the first &quot; &quot;argument and then the directory containing the facial images./n&quot; &quot;For example, if you are in the python_examples folder then &quot; &quot;execute this program by running:/n&quot; &quot; ./face_landmark_detection.py shape_predictor_68_face_landmarks.dat ../examples/faces/n&quot; &quot;You can download a trained facial shape predictor from:/n&quot; &quot; http://sourceforge.net/projects/dclib/files/dlib/v18.10/shape_predictor_68_face_landmarks.dat.bz2&quot;) exit()predictor_path = sys.argv[1]faces_folder_path = sys.argv[2]detector = dlib.get_frontal_face_detector()predictor = dlib.shape_predictor(predictor_path)win = dlib.image_window()for f in glob.glob(os.path.join(faces_folder_path, &quot;*.jpg&quot;)): print(&quot;Processing file: &#123;&#125;&quot;.format(f)) img = io.imread(f) win.clear_overlay() win.set_image(img) # Ask the detector to find the bounding boxes of each face. The 1 in the # second argument indicates that we should upsample the image 1 time. This # will make everything bigger and allow us to detect more faces. dets = detector(img, 1) print(&quot;Number of faces detected: &#123;&#125;&quot;.format(len(dets))) for k, d in enumerate(dets): print(&quot;Detection &#123;&#125;: Left: &#123;&#125; Top: &#123;&#125; Right: &#123;&#125; Bottom: &#123;&#125;&quot;.format( k, d.left(), d.top(), d.right(), d.bottom()))# Get the landmarks/parts for the face in box: d.shape = predictor(img, d) print(&quot;Part 0: &#123;&#125;, Part 1: &#123;&#125; ...&quot;.format(shape.part(0), shape.part(1)))# Draw the face landmarks on the screen.win.add_overlay(shape)win.add_overlay(dets)dlib.hit_enter_to_continue() 简化代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566# -*- coding: utf-8 -*-import dlibimport numpyfrom skimage import io#源程序是用sys.argv从命令行参数去获取训练模型，精简版我直接把路径写在程序中了predictor_path = &quot;./data/shape_predictor_68_face_landmarks.dat&quot;#源程序是用sys.argv从命令行参数去获取文件夹路径，再处理文件夹里的所有图片#这里我直接把图片路径写在程序里了，每运行一次就只提取一张图片的关键点faces_path = &quot;./data/3.jpg&quot;#与人脸检测相同，使用dlib自带的frontal_face_detector作为人脸检测器detector = dlib.get_frontal_face_detector()#使用官方提供的模型构建特征提取器predictor = dlib.shape_predictor(predictor_path)#使用dlib提供的图片窗口win = dlib.image_window()#使用skimage的io读取图片img = io.imread(faces_path)#绘制图片win.clear_overlay()win.set_image(img) #与人脸检测程序相同,使用detector进行人脸检测 dets为返回的结果dets = detector(img, 1)#dets的元素个数即为脸的个数print(&quot;Number of faces detected: &#123;&#125;&quot;.format(len(dets)))#使用enumerate 函数遍历序列中的元素以及它们的下标#下标k即为人脸序号#left：人脸左边距离图片左边界的距离 ；right：人脸右边距离图片左边界的距离 #top：人脸上边距离图片上边界的距离 ；bottom：人脸下边距离图片上边界的距离for k, d in enumerate(dets): print(&quot;dets&#123;&#125;&quot;.format(d)) print(&quot;Detection &#123;&#125;: Left: &#123;&#125; Top: &#123;&#125; Right: &#123;&#125; Bottom: &#123;&#125;&quot;.format( k, d.left(), d.top(), d.right(), d.bottom())) #使用predictor进行人脸关键点识别 shape为返回的结果 shape = predictor(img, d) #获取第一个和第二个点的坐标（相对于图片而不是框出来的人脸） print(&quot;Part 0: &#123;&#125;, Part 1: &#123;&#125; ...&quot;.format(shape.part(0), shape.part(1))) #绘制特征点 win.add_overlay(shape)#绘制人脸框win.add_overlay(dets)#也可以这样来获取（以一张脸的情况为例）#get_landmarks()函数会将一个图像转化成numpy数组，并返回一个68 x2元素矩阵，输入图像的每个特征点对应每行的一个x，y坐标。def get_landmarks(im): rects = detector(im, 1) return numpy.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()])#多张脸使用的一个例子def get_landmarks_m(im): dets = detector(im, 1) #脸的个数 print(&quot;Number of faces detected: &#123;&#125;&quot;.format(len(dets))) for i in range(len(dets)):facepoint = np.array([[p.x, p.y] for p in predictor(im, dets[i]).parts()])for i in range(68): #标记点 im[facepoint[i][1]][facepoint[i][0]] = [232,28,8] return im#打印关键点矩阵print(&quot;face_landmark:&quot;)print(get_landmarks(img))#等待点击dlib.hit_enter_to_continue() 效果实例： 参考文档：http://www.th7.cn/Program/Python/201511/706515.shtml","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"Python","slug":"Python","permalink":"http://blog.killyliu.com/tags/Python/"}]},{"title":"人脸识别(3)--Python3.6+dlib19.4在Mac下环境搭建","date":"2017-04-20T05:28:38.000Z","path":"2017/04/20/人脸识别-3-Python3-6-dlib19-4在Mac下环境搭建/","text":"前面讲到用OpenCV实现简单的人脸识别，这里用dlib实现关键点检测。 前提条件系统环境：这里是在mac系统下进行开发的，其他系统仅供参考。Python：安装python3.6环境(具体操作见之前的博客)。 dlib之前的准备进入终端安装一系列可能用到的包：安装easy-install：1$ sudo pip install python-setuptools 安装python-dev：1$ sudo pip install python-dev 安装numpy：1$ sudo pip install numpy 安装PIL：1$ sudo pip install Image 安装scipy：1$ sudo apt-get install python-scipy 安装matplotlib：1$ sudo apt-get install python-matplotlib 安装dlib依赖dlib安装需要的依赖有openblas，opencv：12$ brew install openblas$ brew install opencv dlib的so库需要的依赖libboost：1$ sudo pip install libboost-python-dev cmake 安装Mac的X11：&emsp;&emsp;X11是执行Unix程序的图形窗口环境。Mac OS X本身的程序是Aqua界面的，但是为了能够兼容unix和Linux移植过来的程序，需要x11窗口环境。 &emsp;&emsp;运行dlib需要X11，但Mac目前没有自带X11，需要重新下载安装，下载地址为：https://www.xquartz.org/，下载后直接安装，默认安装目录为/opt/X11，需要在/usr/loca/opt目录下创建软连接，创建命令如下，创建后重启Mac。12$ cd /usr/local/opt$ ln -s /opt/X11 X11 安装dlib进入dlib官网下载安装包http://dlib.net/，选择合适位置解压。或者使用git下载：1$ git clone https://github.com/davisking/dlib.git 下载完成后进行解压与安装：12345$ cd dlib/examples$ mkdir build$ cd build$ cmake .. $ cmake --build . --config Release 安装dlib中的python模块：在dlib-18.17及之前的版本中，之后进入python_examples下使用bat文件进行编译，编译需要先安装libboost-python-dev和cmake。12$ cd to dlib-18.17/python_examples$ ./compile_dlib_python_module.bat 在18.18及之后，采用新的方式，用setup.py安装生成so依赖文件：12$ cd dlib$ sudo python setup.py install 在得到dlib.so之后将其复制到dist-packages目录下：1$ sudo cp dlib.so /usr/local/lib/python3.6/dist-packages/ 设置python环境变量：12\\# Put the following line in .bashrc or .profile$ export PYTHONPATH=/path/to/dlib/python_examples:$PYTHONPATH 之后再安装一些可能会用到的依赖包：安装skimage1$ sudo pip install python-skimage 安装imtools1$ sudo pip install imtools 实例检测实例1（会出现X11窗口，打开Mac摄像头自动检测人脸并标注人脸的landmar）：12345$ cd dlib/examples/build/#下载face landmark模型$ wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2# 解压文件$ ./webcam_face_pose_ex 实例2（显示有人脸标记的图片）：1$ ./face_landmark_detection_ex shape_predictor_68_face_landmarks.dat ../faces/2008_002506.jpg 参考文档： http://www.learnopencv.com/facial-landmark-detection/ http://blog.csdn.net/Quincuntial/article/details/53572415 http://www.th7.cn/Program/Python/201511/706515.shtml","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"Python","slug":"Python","permalink":"http://blog.killyliu.com/tags/Python/"}]},{"title":"人脸识别(2)--Python3.6+OpenCV3.2识别实例","date":"2017-04-20T05:28:23.000Z","path":"2017/04/20/人脸识别-2-Python3-6-OpenCV3-2识别实例/","text":"前提条件：确保python+opencv环境已经搭建成功(搭建步骤可以参考上一篇博客)。 调用摄像头获取图片进行实时检测调用摄像头，可以看到头像用方框框起来，并实时根据情况调整位置。1234567891011121314151617181920212223242526272829303132#!/usr/bin/env python#coding=utf-8import cv2import numpy as npcv2.namedWindow(&quot;test&quot;)cap=cv2.VideoCapture(0) success, frame = cap.read()color = (0,0,0)classfier=cv2.CascadeClassifier(&quot;/Users/liuqi/opencv/data/haarcascades/haarcascade_frontalface_alt.xml&quot;)while success: success, frame = cap.read() size=frame.shape[:2] image=np.zeros(size,dtype=np.float16) image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) cv2.equalizeHist(image, image) divisor=8 h, w = size minSize =(w//divisor, h//divisor) faceRects = classfier.detectMultiScale(image, 1.2, 2, cv2.CASCADE_SCALE_IMAGE,minSize) if len(faceRects)&gt;0: for faceRect in faceRects: x, y, w, h = faceRect cv2.rectangle(frame, (x, y), (x+w, y+h), color) cv2.imshow(&quot;test&quot;, frame) key=cv2.waitKey(10) c = chr(key &amp; 255) if c in [&apos;q&apos;, &apos;Q&apos;, chr(27)]: breakcv2.destroyWindow(&quot;test&quot;) 识别结果实例： 本地获取图片进行人脸检测并保存图片从本地路径获取图片，识别人脸后将结果图片再保存在本地。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#!/usr/bin/env python#coding=utf-8import osimport sysfrom PIL import Image, ImageDrawimport numpy as npimport cv2#import dlibdef detect_object(infile, save_path): image = cv2.imread(infile) &apos;&apos;&apos;检测图片，获取人脸在图片中的坐标&apos;&apos;&apos; size=image.shape[:2]#获得当前桢彩色图像的大小 #image_set=np.zeros(size,dtype=np.float16)#定义一个与当前桢图像大小相同的的灰度图像矩阵 image_grey = np.zeros(size, np.uint8)#创建一个空白图片 #image_grey = Image.new(mode= &quot;RGBA&quot;,size = size, color = (117,255,0)) #image_grey = cv2.imread(img_grey) grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)#将当前桢图像转换成灰度图像 #img_binary = cv2.threshold(image,127,255,0)#将灰度图片转化为二进制图片 color = (135,206,250) #设置人脸框的颜色 #eye_cascade = cv2.CascadeClassifier(&apos;/Users/liuqi/opencv/data/haarcascades/haarcascade_eye.xml&apos;) classfier=cv2.CascadeClassifier(&quot;/Users/liuqi/opencv/data/haarcascades/haarcascade_frontalface_alt.xml&quot;) #人脸检测，1.2和2分别为图片缩放比例和需要检测的有效点数 faceRects = classfier.detectMultiScale(grey, scaleFactor = 1.3, minNeighbors = 4, minSize = (32, 32)) result = [] im = Image.open(infile) if len(faceRects) &gt; 0: #大于0则检测到人脸 draw = ImageDraw.Draw(im) num = 0 for faceRect in faceRects: num += 1 #单独框出每一张人脸 x, y, w, h = faceRect #画出矩形框 #cv2.rectangle(image_grey, (x - 10, y - 10), (x + w + 10, y + h + 10), color, 2) cv2.rectangle(grey, (x - 10, y - 10), (x + w + 10, y + h + 10), color, 2) a = im.crop(faceRect) file_name = os.path.join(save_path,str(num)+&quot;.jpg&quot;) #a.save(file_name) &apos;&apos;&apos;保存新生成的图片&apos;&apos;&apos; #将当前帧保存为图片 #cv2.imwrite(file_name,image_grey) cv2.imwrite(file_name,grey) drow_save_path = os.path.join(save_path,&quot;out.jpg&quot;) im.save(drow_save_path, &quot;JPEG&quot;, quality=80) else: print (&quot;Error: cannot detect faces on %s&quot; % infile) return 0def process(infile): #获取图片，进行检测 #image = cv2.imread(infile) &apos;&apos;&apos;在原图上框出头像并且截取每个头像到单独文件夹&apos;&apos;&apos; #创建输出图片的路径 #im = Image.open(infile) path = os.path.abspath(infile) save_path = os.path.splitext(path)[0]+&quot;_face&quot; try: os.mkdir(save_path) except: pass faces = detect_object(infile, save_path)if __name__ == &quot;__main__&quot;: process(&quot;/Users/liuqi/Desktop/2.jpg&quot;) 实现的效果如下：选取的图片与识别后的图片： &emsp;","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"Python","slug":"Python","permalink":"http://blog.killyliu.com/tags/Python/"}]},{"title":" 人脸识别(1)--Python3.6+OpenCV3.2在Mac下环境搭建","date":"2017-04-20T05:28:04.000Z","path":"2017/04/20/人脸识别-1-Python3-6-OpenCV3-2在Mac下环境搭建/","text":"&emsp;&emsp;现在越来越多的地方需要用到智能识别，这里先介绍一种简单的用方框实现人脸检测的环境。 python安装从官网上下载最新版本的python，这里我选择了dmg文件，直接双击进行安装。python官网;https://www.python.org/downloads/mac-osx/ 之后需要更新一下PATH路径:打开cmd，在~/.bash_profile中添加（如果不存在进行添加）12$ vim ~/.bash_profileexport PATH=/usr/local/bin:$PATH 然后重新加载~/.bash_profile，保证更新成功:1$ source ~/.bash_profile 确认python安装成功:1234$ which python3/usr/local/bin/python$ python3 --versionPython 3.6.1 搭建python虚拟环境虽然虚拟环境不是必须的步骤，但是鉴于我们可能用电脑开发很多不同的项目，所以强烈建议新建一个虚拟环境用于python的opencv开发。 首先，安装虚拟环境 virtualenv 和 virtualenvwrapper:1$ pip3 install virtualenv virtualenvwrapper 这个虚拟环境是在python环境中都可以用的。这里我们更新~/.bash_profile 的设置:123#Virtualenv/VirtualenvWrapperexport VIRTUALENVWRAPPER_PYTHON=/usr/local/bin/python3source /usr/local/bin/virtualenvwrapper.sh 然后重新加载.bash_profile:1$ source ~/.bash_profile 现在我们创建一个cv3的虚拟环境进行开发，便于安装一些这个项目需要的额外的包，并进行图片处理。1$ mkvirtualenv cv3 -p python3 在 mkvirtualenv 之后会自动进入cv3环境，但如果是已经存在这个环境，想再次进入环境的话，用worken:1$ workon cv3 可以进入cv3环境。在这个虚拟环境中，我们需要安装numpy（python的先决条件）1$ pip install numpy 安装openVC的先决条件为了编译openVC，需要安装一些开发工具:1$ brew install cmake pkg-config 同时下载一些用于各种图片格式读取的包:1$ brew install jpeg libpng libtiff openexr 以及另外一些包用于优化openVC程序:1$ brew install eigen tbb 编译openVC环境从Github上下载openVC源码（可以从官网上选择最新的版本进行检出）:注： Github地址：https://github.com/opencv/opencv1234$ cd ~$ git clone https://github.com/Itseez/opencv.git$ cd opencv$ git checkout 3.2.0 之后，我们需要下载opencv_contrib包，为OpenCV提供一些额外的支持，像内容检测等(这里我们选择和OpenCV相同的版本进行下载)1234$ cd ~$ git clone https://github.com/Itseez/opencv_contrib$ cd opencv_contrib$ git checkout 3.2.0 在下载完成后，创建build文件夹:123$ cd ~/opencv$ mkdir build$ cd build 使用CMake进行build:注：这里要确认OpenCV和python3模块都加载完成。12345678910$ cmake -D CMAKE_BUILD_TYPE=RELEASE \\ -D CMAKE_INSTALL_PREFIX=/usr/local \\ -D PYTHON3_PACKAGES_PATH=~/.virtualenvs/cv3/lib/python3.4/site-packages \\ -D PYTHON3_LIBRARY=/usr/local/Cellar/python3/3.4.3/Frameworks/Python.framework/Versions/3.4/lib/libpython3.4m.dylib \\ -D PYTHON3_INCLUDE_DIR=/usr/local/Cellar/python3/3.4.3/Frameworks/Python.framework/Versions/3.4/include/python3.4m \\ -D INSTALL_C_EXAMPLES=ON \\ -D INSTALL_PYTHON_EXAMPLES=ON \\ -D BUILD_EXAMPLES=ON \\ -D BUILD_opencv_python3=ON \\ -D OPENCV_EXTRA_MODULES_PATH=~/opencv_contrib/modules .. 当CMake完成并且不报错之后，开始进行编译:12$ make -j4$ make install 若权限不足，则使用下面语句:12$ make -j4$ sudo make install 安装验证验证cv2.so正确:123$ cd ~/.virtualenvs/cv3/lib/python3.4/site-packages/$ ls -l cv2.so-rwxr-xr-x 1 admin _developer 2017027 April 14 06:11 cv2.so 验证python中可以使用opencv包，import不报错:1234Python 3.6.1 (v3.6.1:69c0db5050, Mar 21 2017, 01:21:04) [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwinType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import cv2 参考文档：https://www.pyimagesearch.com/2015/06/29/install-opencv-3-0-and-python-3-4-on-osx/","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"Python","slug":"Python","permalink":"http://blog.killyliu.com/tags/Python/"}]},{"title":"Repo的理解及用法小结(2)","date":"2017-04-18T03:07:00.000Z","path":"2017/04/18/Repo的理解及用法小结-2/","text":"&emsp;&emsp;之前已经讲了Repo的基本理解，这里总结一下Repo的常用命令。 1. repo init1repo init -u manifest_git_path -m manifest_file_name -b branch_name --repo-url=repo_url --no-repo-verify &emsp;&emsp;在当前目录下安装 Repo。这会产生一个 .repo/ 目录，目录包括装 Repo 源代码和标准 Android 清单文件的 Git 仓库。.repo/ 目录还包括 manifest.xml，是一个在 .repo/manifests/ 目录选择清单的符号链接。&emsp;&emsp;选项： -u: 指定Manifest库的Git访问路径。-m: 指定要使用的Manifest文件。-b: 指定要使用Manifest仓库中的某个特定分支。–repo-url: 指定要检查repo是否有更新的远端repoGit库的访问路径。–no-repo-verify: 指定不检查repo库是否需要更新。 2. repo sync1repo sync [project_name] &emsp;&emsp;用于参照清单文件克隆并同步版本库。可以使用repo sync project_name的形式只克隆某个项目。。&emsp;&emsp;实现参照清单.repo/manifests.xml克隆并同步版本库，如果版本库不存在，则相当于执行1git clone &emsp;&emsp;如果版本库已经存在，则相当于执行1234#对每个remote源进行fetch操作git remote update#针对当前分支的跟踪分支进行rebase操作git rebase/origin/branch &emsp;&emsp;选项： -d：切换指定项目回到清单修正。如果该项目目前是一个主题分支那就有帮助，但清单修正是暂时需要。-s：同步到一个已知的构建 manifest-server 在当前清单指定的元素。-f：继续同步其他项目，即使有项目同步失败。 3. repo start1repo start &lt;newbranchname&gt; [--all|&lt;project&gt;...] &emsp;&emsp;创建并切换分支。刚克隆下来的代码是没有分支的，repo start实际是对git checkout -b命令的封装。&emsp;&emsp;为指定的项目或所有的项目（若使用-all），以清单文件中为设定的分支，创建特定的分支。&emsp;&emsp;这条指令与git checkout -b 还是有很大区别的。&emsp;&emsp;· git checkout -b 是在当前所在的分支的基础上创建特性分支。&emsp;&emsp;· 而repo start 是在清单文件设定的分支的基础上创建特性分支。1repo start stable --all &emsp;&emsp;假设清单文件中设定的分支是gingerbread-exdroid-stable，那么执行以上指令就是对所有项目，在gingerbread-exdroid-stable的基础上创建特性分支stable。1repo start stable platform/build platform/bionic &emsp;&emsp;假设清单文件中设定的分支是gingerbread-exdroid-stable，那么执行以上指令就是对platform/build、platform/bionic项目，在gingerbread-exdroid-stable的基础上创建特性分支stable。 4. repo checkout123&lt;branchname&gt; [&lt;rpoject&gt;...]&#123;&#123;&#123; repo checkout &lt;branchname&gt; [&lt;project&gt;...]&#125;&#125;&#125; &emsp;&emsp;切换分支。 实际上是对git checkout命令的封装，但不能带-b参数，所以不能用此命令来创建特性分支。&emsp;&emsp;示例：12repo checkout liuq-devrepo checkout liuq-dev skipper/build platform/bionic 5. repo branches1repo branches [&lt;project&gt;...] &emsp;&emsp;查看分支。&emsp;&emsp;示例：12345repo branchesrepo branches skipper/build skipper/release#查看可切换的分支cd .repo/manifestsgit branch -a | cut -d / -f 3 6. repo diff1repo diff [&lt;project&gt;...] &emsp;&emsp;查看工作区文件差异。实际是对git diff命令的封装，用于分别显示各个项目工作区下的文件差异。在 commit 和工作目录之间使用 git diff 显示明显差异的更改。&emsp;&emsp;示例：1234#查看所有项目repo diff#只查看其中的两个项目repo diff skipper/build skipper/release 7. repo stage1repo stage -i [&lt;project&gt;...] &emsp;&emsp;把文件添加到index表中。实际上是对git add –interactive命令的封装，用于挑选各个项目中的改动以加入暂存区。&emsp;&emsp;-i表示git add –interactive命令中的–interactive，给出一个界面供用户选择。 8. repo prune1repo prune [&lt;project&gt;...] &emsp;&emsp;删除已经合并分支。实际上是对git branch -d 命令的封装，该命令用于扫描项目的各个分支，并删除已经合并的分支。 9. repo abandon1repo abandon &lt;branchname&gt; [&lt;rpoject&gt;...] &emsp;&emsp;删除指定分支。实际是对git brance -D命令的封装。 10. repo status1repo status [&lt;project&gt;...] &emsp;&emsp;查看文件状态。&emsp;&emsp;示例：12#输出skipper/build项目分支的修改状态repo status skipper/build 每个小节的首行显示项目名称，以及所在的分支的名称。每个字母表示暂存区的文件修改状态。 字母 含义 描述 - 无变化 没有修改，在 HEAD 和在索引中是一样的 A 添加 不在HEAD中，在暂存区中 M 修改 在HEAD中， 在暂存区中，内容不同 D 删除 在HEAD中，不在暂存区 R 重命名 不在HEAD中，在暂存区中 C 拷贝 不在HEAD中，在暂存区，从其他文件拷贝 T 文件状态改变 在HEAD中，在暂存区，内容相同 U 未合并 需要冲突解决 第二个字符表示工作区文件的更改状态。 字母 含义 描述 - 新/未知 不在暂存区，在工作区 m 修改 在暂存区，在工作区，被修改 d 删除 在暂存区，不在工作区 两个表示状态的字母后面，显示文件名信息。如果有文件重名还会显示改变前后的文件名及文件的相似度。 11. repo remote12repo remote add &lt;remotename&gt; &lt;url&gt; [&lt;project&gt;...]repo remote rm &lt;remotename&gt; [&lt;project&gt;...] &emsp;&emsp;设置远程仓库。&emsp;&emsp;示例：1repo remote add org ssh://10.11.10.11/git_repo &emsp;&emsp;这个指令根据xml文件添加的远程分支，方便于向服务器提交代码，执行之后的build目录下看到新的远程分支org。12#删除远程仓库repo remote rm org 12. repo push1repo push &lt;remotename&gt; [--all|&lt;project&gt;...] &emsp;&emsp;向服务器提交代码。repo会自己查询需要向服务器提交的项目并提示用户。&emsp;&emsp;示例：1repo push org 13. repo forall1repo forall [&lt;project&gt;...] -c &lt;command&gt; &emsp;&emsp;迭代器，可以在所有指定的项目中执行同一个shell指令。&emsp;&emsp;选项： -c 后面所带的参数是shell指令，即执行命令和参数。命令是通过 /bin/sh 评估的并且后面的任何参数就如 shell 位置的参数通过。-p 在shell指令输出之前列出项目名称，即在指定命令的输出前显示项目标题。这是通过绑定管道到命令的stdin，stdout，和 sterr 流，并且用管道输送所有输出量到一个连续的流，显示在一个单一的页面调度会话中。-v 列出执行shell指令输出的错误信息，即显示命令写到 sterr 的信息。 &emsp;&emsp;附加环境变量： REPO_PROJECT 指定项目的名称REPO_PATH 指定项目在工作区的相对路径REPO_REMOTE 指定项目远程仓库的名称REPO_LREV 指定项目最后一次提交服务器仓库对应的哈希值REPO_RREV 指定项目在克隆时的指定分支，manifest里的revision属性 &emsp;&emsp;如果-c后面所带的shell指令中有上述环境变量，则需要用单引号把shell指令括起来。 13.1. 添加环境变量12repo forall -c &apos;echo $REPO_PROJECT&apos;repo forall -c &apos;echo $REPO_PATH&apos; 13.2. 合并多个分支1repo forall -p -c git merge topic &emsp;&emsp;把所有项目都切换到master分支，执行上述指令将topic分支合并到master分支。 13.3. 打标签1repo forall -c git tag crane-stable-1.6 &emsp;&emsp;在所有项目下打标签。 13.4. 设置远程仓库1repo forall -c &apos;git remote add korg ssh://xiong@172.16.31/$REPO_PROJECT.git&apos; &emsp;&emsp;引用环境变量REPO_PROJECT添加远程仓库。12#删除远程仓库。repo forall -c git remote rm korg 13.5. 创建特性分支12repo forall -c git branch crane-devrepo forall -c git checkout -b crane-dev 14. repo grep1repo grep &#123;pattern | -e pattern&#125; [&lt;project&gt;...] &emsp;&emsp;打印出符合某个模式的行。相当于对 git grep 的封装，用于在项目文件中进行内容查找。&emsp;&emsp;示例：1234#要找一行, 里面有#define, 并且有&apos;MAX_PATH&apos; 或者 &apos;PATH_MAX&apos;:repo grep -e &apos;#define&apos; --and -\\( -e MAX_PATH -e PATH_MAX \\)#查找一行, 里面有 &apos;NODE&apos;或&apos;Unexpected&apos;, 并且在一个文件中这两个都有的.repo grep --all-match -e NODE -e Unexpected 15. repo manifest1repo manifest [-o &#123;-|NAME.xml&#125; [-r]] &emsp;&emsp;manifest检验工具，用于显示manifest文件内容。&emsp;&emsp;选项: -h, –help 显示这个帮助信息后退出-r, –revision-as-HEAD 把某版次存为当前的HEAD-o -|NAME.xml, –output-file=-|NAME.xml 把manifest存为NAME.xml 16. repo version1repo version &emsp;&emsp;显示repo的版本号。&emsp;&emsp;选项: -h, –help 显示这个帮助信息后退出. 17. repo upload1repo upload [--re --cc] &#123;[&lt;project&gt;]...|--replace &lt;project&gt;&#125; &emsp;&emsp;repo upload 相当于git push，但是又有很大的不同。它不是将版本库改动推送到代码审核服务器（Gerrit软件架设）的特殊引用上，使用SSH协议。代码审核服务器会对推送的提交进行特殊处理，将新的提交显示为一个待审核的修改集，并进入代码审核流程，只有当审核通过后，才会合并到官方正式的版本库中。&emsp;&emsp;选项： -h, –help 显示帮助信息-t 发送本地分支名称到Gerrit代码审核服务器–replace 发送此分支的更新补丁集–re=REVIEWERS 要求指定的人员进行审核–cc=CC 同时发送通知到如下邮件地址 18. repo download1repo download &#123;project change[/patchset]&#125;... &emsp;&emsp;repo download命令主要用于代码审核者下载和评估贡献者提交的修订。&emsp;&emsp;贡献者的修订在Git版本库中refs/changes//引用方式命名（缺省的patchset为1），和其他Git引用一样，用git fetch获取，该引用所指向的最新的提交就是贡献者待审核的修订。&emsp;&emsp;使用repo download命令实际上就是用git fetch获取到对应项目的refs/changes//patchset&gt;引用，并自动切换到对应的引用上。 19. repo selfupdate1repo selfupdate &emsp;&emsp;用于 repo 自身的更新。如果有新版本的repo存在, 这个命令会升级repo到最新版本。通常这个动作在repo sync时会自动去做, 所以不需要最终用户手动去执行。&emsp;&emsp;选项: -h, –help 显示这个帮助信息后退出.–no-repo-verify 不要验证repo源码. 20. repo help1repo help [--all|command] &emsp;&emsp;显示命令的详细帮助。&emsp;&emsp;选项: -h, –help 显示这个帮助信息后退出-a, –all 显示完整的命令列表 参考文档：http://blog.sina.com.cn/s/blog_89f592f50100vpau.htmlhttps://github.com/Trawn/repo-help-zh-cn/blob/master/repo%20help%20zhcn.txt","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"Repo","slug":"Repo","permalink":"http://blog.killyliu.com/tags/Repo/"}]},{"title":"Repo的理解及用法小结(1)","date":"2017-04-17T01:45:09.000Z","path":"2017/04/17/Repo的理解及用法小结-1/","text":"Repo介绍&emsp;&emsp;随之移动终端设备的普及，各企业越来越重视Android市场，而研究Android系统的底层驱动开发，首先需要做的便是建立一套Android版本库管理机制。Android使用Git进行代码管理，而Repo命令行工具对Git命令进行了封装，可以管理多个git项目，从而更好地对代码进行集中式管理。 &emsp;&emsp;Repo是Google用Python脚本写的调用Git的脚本（可以在Google Group 上找到相关文档资料），用于下载、管理Android项目的软件仓库。Repo主要包含Repo配置信息以及Repo锁管理的Git项目集合。 Repo用法安装Repo注：下载Repo只针对第一次使用。首先，确认主目录下存在 bin/ 目录并已包含在路径中：12mkdir ~/binPATH=~/bin:$PATH 下载Repo工具并设置可执行的权限：12curl https://storage.googleapis.com/git-repo-downloads/repo &gt; ~/bin/repochmod a+x ~/bin/repo 注：在Repo设置成功后，会出现下列提示，说明可以进行初始化了。 error: repo is not installed. Use “repo init” to install it here. Repo初始化 (init)首先创建目录用于存放工程文件：12mkdir WORKSPACEcd WORKSPACE 之后，使用命令进行初始化：1repo init -u URL [OPTIONS] 具体操作有： -u：指定一个URL，其连接到一个manifest仓库。-m：在manifest仓库中选择一个 NAME.xml 文件。-b：选择一个manifest仓库中一个特殊的分支。注：· 如果不提供 -b REVISION 或者 –manifest-branch=REVISION参数，则检出 manifest Git 库的 master 分支。· 如果不提供 -m NAME.xml 或者 –manifest-name=NAME.xml 参数，则使用缺省值 default.xml。 在初始化完成后，输入ls命令：1ls repo 可以看到相关文件：manifests/ manifests.git/ manifest.xml repo/ (1) .repo：Repo目录，可用于提取相应项目工作目录到外面的repo工作目录。(2) .repo/manifests.git：Repo配置信息的Git库，不同版本包含不同配置信息。(3) .repo/manifests：Repo配置信息的工作目录（将配置信息的工作目录和相应的实际Git目录分离管理，并且配置信息中的.git目录实际只是指向实际Git库的软连接），其中可能包含一个或多个xml文件描述的配置。每个xml文件是独立的一套配置，配置内容包括当前Repo工作目录包含哪些Git项目、所有Git项目所处的默认公共分支、以及远端地址等。(4) .repo/manifest.xml：Repo工作目录中的内容同一时刻只能采用manifests中的一个xml文件做为其配置，该文件就是其软连接，通过init的-m选项指定采用哪个文件；另外，同一xml文件也可能处于manifests库的不同版本或者不同分支，通过init的-b选项指定使用manifests中的哪个分支，每次init命令都会从服务器更新最新的配置。(5) .repo/repo：Repo脚本集的Git库，这里包含Repo命令所需的所有子命令脚本实现，由Python完成，这个目录本身又由Git来管理。 Repo同步 (sync)下载当前repo配置的所有项目，并生成对应的repo工作目录：1repo sync 如果想生成特定项目的代码，则使用下列语句：1repo sync [&lt;project&gt;...] 实现参照清单.repo/manifests.xml克隆并同步版本库，如果版本库不存在，则相当于执行1git clone 如果版本库已经存在，则相当于执行1234#对每个remote源进行fetch操作git remote update#针对当前分支的跟踪分支进行rebase操作git rebase/origin/branch 同步涉及到的参数有： -j：开启多线程同步操作，会加快sync命令的执行速度。默认情况下，使用4个线程并发进行sync。-c, –current-branch：只同步指定的远程分支。默认情况下，sync会同步所有的远程分支，当远程分支比较多的时候，下载的代码量就大。使用该参数，可以缩减下载时间，节省本地磁盘空间。-d, –detach：脱离当前的本地分支，切换到manifest.xml中设定的分支。在实际操作中这个参数很有用，当我们第一次sync完代码后，往往会切换到dev分支进行开发。如果不带该参数使用sync， 则会触发本地的dev分支与manifest设定的远程分支进行合并，这会很可能会导致sync失败。-f, –force-broken：当有git库sync失败了，不中断整个同步操作，继续同步其他的git库。–no-clone-bundle：在向服务器发起请求时，为了做到尽快的响应速度，会用到内容分发网络(CDN, Content Delivery Network)。同步操作也会通过CDN与就近的服务器建立连接， 使用HTTP/HTTPS的$URL/clone.bundle来初始化本地的git库，clone.bundle实际上是远程git库的镜像，通过HTTP直接下载，这会更好的利用网络带宽，加快下载速度。 同步完成后，.repo下多了projects目录，，原工作目录下也多了目录： (1) .repo/projects：Repo所管理的所有Git项目集，包含Repo当前配置所指定的所有Git项目对应的Git目录。(2) .repo/../ :Repo的工作区。在Repo目录（即.repo）之外，根据Repo配置（即.repo/manifest.xml文件），从.repo/projects下提取出指定分支的各个Git项目（即.repo/projects中Git项目的子集）的工作目录，形成Repo工作目录，可供开发使用。 注：以上内容参考链接http://blog.chinaunix.net/uid-9525959-id-4534319.htmlhttp://www.360doc.com/content/14/0220/17/97538_354256755.shtml","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"Repo","slug":"Repo","permalink":"http://blog.killyliu.com/tags/Repo/"}]},{"title":"《黑洞》背后的思考","date":"2017-04-10T02:52:16.000Z","path":"2017/04/10/《黑洞》背后的思考/","text":"&emsp;&emsp;其实最初是想写关于《人民的名义》观看感想的，但思来想去，现在只播出不到一半而已，而且对于最高人民检察院影视中心的组织创作，个人还是寄予了很高的期望。&emsp;&emsp;因而，决定先回顾一部很多年前的反腐老剧《黑洞》，真实、黑暗，又不颓废、不做作。 人性是物性的绽放&emsp;&emsp;”当我们相信自己对这个世界已经相当重要的时候，其实这个世界才刚刚准备原谅我们的幼稚。”再次追剧后，对《少年凯哥》中的这句话有了更深刻的理解。我们总以为自己看懂了一些事，明白了一些物，就可以笑傲江湖。但其实百年岁月仅三千瓢中一引，殊不知天很高，地很厚，水很深。 &emsp;&emsp;刘振汉：这个世界上总有那么一群人，有自己的原则，这个原则不包含任何东西，甚至自己最亲近的人，只为心中的那份执着，那份正义。这样子的人在外人看来，有些异类。但从大局上讲，这样的人是值得尊敬的。 &emsp;&emsp;聂明宇：并非一个纯粹的坏人，只是选择了在处理事情上顺从内心阴暗面的处理方法，以至于走向犯罪的深渊，触犯了法律的高压线。但其实他的一系列行为借用那句“我本是活腻了的人”，只是用不恰当的行为对周边实施了报复，以填补内心的缺失。 &emsp;&emsp;两位各有自己的性格，也各有自己坚守，同样也各有各的得失。这种人性的矛盾成为整个剧的粘合剂。性有如一团颜色各异缠丝，包含着众多的情感，包含着众多的人情事故，也包含着众多的道德准则和自我立场。而不同的抽丝选择，决定了不同的余留种类。 &emsp;&emsp;现实不等于真实、真实不等于真相、真相不等于真理、真理不等于智慧，智慧不等于平凡，最后落在平凡，又和我们的平凡不太一样，是让所有的生命完成和解，和解不是妥协，不是谅解。 &emsp;&emsp;现实社会是在正义、道德等掩饰性词语的背后正恶平衡推动的。对与错没有唯一的标准，智慧、力量、勇气、美好永远都是人们渴求的，而善良，一直是人类发展中的奢侈品。在当时的社会，不谈什么正义、公平、法制，能有自己精神的内核就已经超越了社会的大多数。 经济发展与社会生活的黑洞&emsp;&emsp;《黑洞》中所提到的天都市属于杜撰，这个城市究竟是哪里并不重要，真正重要的是埋在这个城市的土里的时代印记。世纪之交，很多城市看起来繁荣昌盛，发展稳定，但是地下却暗流涌动。时代的发展就像是巨大的车轮无情地碾过，人在很多时候在欲望和权利面前被推着向前走，正如那几乎一手遮天的天都市。 &emsp;&emsp;社会道德和社会良知的黑洞笼罩着天都市，正义与邪恶看似一线之隔，但从黑洞一角抽丝剥茧，你会发现没有尽头，很多事情远比想象中复杂，比预计更艰难。刘振汉的纠结与果敢，聂明宇的从容与不安，龚倩的性情与执念，张峰的绝情与无奈，王明的急性与奉献，小芮的狠毒与忠心，贺清明的胆怯与良善，人性的两面，在此彰显。 &emsp;&emsp;当片尾的音乐前奏响起，冗长而低沉的男声渐吟，那一幕幕黑白交替的画面就这样映射在脑海中，被悲伤与黑暗笼罩着的这个名叫天都的城市，如同深渊一般，将故事里的每一个人都搅进了这个黑洞的漩涡之中。然而，它最终还是无情地制造出了一场悲剧。 &emsp;&emsp;“这些高墙还真是有点意思。一开始你恨它，然后你对它就习惯了。等相当的时间过去后，你还会依赖它。”大势所向，螳臂当车。可大势之外有大势，小小的螳螂怎么看到的天？","tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.killyliu.com/tags/随笔/"}]},{"title":"她是七月，也是安生","date":"2017-04-05T09:43:18.000Z","path":"2017/04/05/她是七月，也是安生/","text":"&emsp;&emsp;很早之前就读过安妮宝贝的这篇小说，些许矛盾，又太过苍白。前两天偶然间看到了电影片段，周冬雨那强忍着眼泪的镜头令人感到莫名心酸，决定认真看一次影视版的《七月与安生》。不得不说，改编后的电影真心很棒，并未落入俗套，而且情节也更加合理。 渴望极致的自由，也想要无悔的安定&emsp;&emsp;从小如影相随的七月和安生，一个装疯一个卖乖，一起在生活中叛逆，又一起憧憬着未来。她们朝夕陪伴互相依赖，是彼此的快乐和慰藉。 &emsp;&emsp;正如电影的英文版标题soulmate，看起来完全不同的两人走在一起并非偶然，其实对方都是自己心里所渴望的那个截然不同的自己，或安静，或放肆，或叛逆，或崇高，或虚伪。七月的温婉安静，是因为她在压抑自我；安生的洒脱不羁，更像是为了掩盖内心对于爱的渴望。 &emsp;&emsp;七月那么安静可爱学习优秀前途大好充满了安全感，安生那么活泼灵动叛逆不羁充满了不确定感。而苏家明是一个青春里的符号，学习优秀、长相端正、品行优良，挺拔，有温暖的笑容，是男神，也是邻家男孩。 &emsp;&emsp;优秀内敛的七月爱上家明，再自然不过。&emsp;&emsp;英俊温和的家明接受七月，再自然不过。 &emsp;&emsp;淳朴端正的家明遇上安生，没有躲过，再正常不过。&emsp;&emsp;叛逆不羁的安生遇上家明，也动心了，再正常不过。 &emsp;&emsp;谁不需要安全感中的稳定，而谁又不需要不确定感中的诱惑。苏家明与七月是日久生情，爱七月是顺其自然；而对安生是一见钟情，爱安生是命运使然。自始至终，苏家明都在摇摆。徘徊在两个女孩儿之间，徘徊在现实与梦之间，多情却理智，聪明却迷茫。他就像一条自由与温暖的分界线，横亘在七月与安生之间，成为她们的芥蒂，却也将彼此紧紧联结。 此岸与彼岸，一个被选择的结果 &emsp;&emsp;其实两人最初的选择都只是合适而已。七月问“你真的爱他吗？”。“他天天唱歌给我听，跟我一起喝酒，一起睡觉，就差没有跟我们俩一样一起洗澡了。”安生没有正面回答，就像当初安生问七月是否真的很爱家明，七月也没有正面回答，只是说“他长得帅，还是田径队的。” &emsp;&emsp;安生为了七月选择了离开，越走越远。去不同的城市，见不同的人，过不同但始终是漂泊的生活。七月则按部就班的生活，安稳的学习，安稳的工作。安生四海为家,走过千山万水，哭过、笑过、闹过、悲伤过、无奈过。在七月看来，这样丰富多彩的生活，其实她是挺羡慕的，比自己“一眼就可以看到一生”的安稳要精彩很多。 &emsp;&emsp;性格相似的适合为友，互补的适合做恋人。但其实反过来也一样。一段稳固的感情，无非就是求同存异。完全相像或者完全相反的人，不会擦出火花。七月是安生的渴望,渴望像她一样的安稳。安生是七月的向往，向往她自由自在的生活。 &emsp;&emsp;“你是什么人，可能家明不知道，那我还不清楚吗？”的确，七月与安生彼此都太了解彼此，而两个人在彼此面前又都是自卑的，在摩擦中互相折磨，在羡慕中互相妒恨。好像自己被一些人吸引着，同时对他们向住着，但心里却妒忌着。 我活成了你，我也只有你&emsp;&emsp;安生对七月像是要抓住浮萍往岸上爬，她不想要那么多狗血、那么多诡谲，只想静静地把心熨平整。经历了生活苦难，尝尽人间辛酸的女孩儿是懂事的，体贴的，犹如她用“不，每个人都不容易的”来回答七月那句任性的“你以为我这些年就容易吗？” &emsp;&emsp;七月展现着自己与安生的不同，解释着苏家明喜欢的是细水长流的小幸福而不是变幻莫测的新鲜刺激。情不知所起，一往而深；而恨见缝插针，无处躲藏。 &emsp;&emsp;她们是彼此的另一面。她回来了，她走了。两个最好的朋友，彼此珍惜着，又彼此羡慕着，两个人通过对方去感受着不同的生活。最后的最后，七月变成了安生，安生也成了七月。就像人生的戏，改变了一下出场的顺序，却是不一样的结局。 &emsp;&emsp;她们是不幸的，当年长后，当彼此终于成熟到能意识到家明不过就是她们友谊中的一次大事故，而她们不值的为事故而放弃她们爱的生命时，七月却永远离去。只留下安生永远留下咀嚼这青春往事。但她们也幸运的。随着七月的离去，友谊长存了，她们彻底融解了，她们永远活在了27岁前，永远是青春里为爱可以放逐自己，为爱可以隐忍自己，彼此都是彼此心头一袭明月的那两个女孩。永远年轻。 &emsp;&emsp;曾经那些炙热的、拼了命想要的，都不重要了。绕了一大圈、一大圈，安生终于心安了。七月也是，电影的最后七月一个人走在遍地雪白的道路上，向前走，好像也已经找到了自己的归处。 &emsp;&emsp;“过得折腾一点，也不一定不幸福，就是太辛苦了。但其实，女孩子不管走哪条路，都是会辛苦的。”&emsp;&emsp;“我知道。”&emsp;&emsp;“希望我的女儿能是个例外。” &emsp;&emsp;我想七月母亲的话适用于任何人，我们既渴望漂泊又渴望安稳，我们既想要辛苦的折腾，又想要成为一个例外。“七月心里很清楚，从那一刻起，自己和安生注定要过上截然不同的人生。”终有一段路是一边哭一边走完。","tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.killyliu.com/tags/随笔/"}]},{"title":"博客搭建(2)--Mac下用Hexo搭建个人博客","date":"2017-04-04T07:54:30.000Z","path":"2017/04/04/博客搭建-2-Mac下用Hexo搭建个人博客/","text":"在此之前，有人推荐使用jekyll，有人推荐hexo，因而上网查找资料进行简单对比： Jekyll基于Ruby， Hexo基于NodeJs。 两者都支持Markdown。 Jekyll的主题相对而言没有Hexo的美观（个人见解） 对于网上所说的Jekyll没有本地服务器，需要纠正一下，其实两者都可以实现本地预览功能，再发布到容器中同步。根据个人喜好进行选择，这里我选择了hexo。 准备工作1. 安装node.js 安装语句：brew install node 2. 已搭建git环境（或者github管理软件） 使用语句查看安装成功：node -vnpm -vgit –version 初始化Github环境在上一篇博客中已经建好了网站，这里直接克隆到本地便于接下来的操作。选定博客搭建路径后，将仓库克隆到本地： git clone https://github.com/Killy-LIU/killy-liu.github.io.gitcd killy-liu.github.io/git init 安装Hexo并搭建网站 1. 安装执行命令： sudo npm install -g hexo-cli 2. 从控制台进入克隆的文件夹目录下，进行初始化hexo： hexo init 3. 在初始化完成之后，执行本地服务化发现报错。因而重新进行安装配置。 npm install 文件夹目录结构 source：博客资源文件夹source/_drafts：草稿文件夹source/_posts：文章文件夹themes：存放主题的文件夹themes/landscape：默认的主题_config.yml：全局配置文件 4. 进行本地服务测试。 hexo server 输入 http://localhost:4000/ 即可打开默认页面： 跳坑： 这里曾经因为无法启动本地服务器，尝试过许多方法(如下)，均无法解决错误 Cannot find module ‘./build/Release/DTraceProviderBindings’，以下是曾经尝试过的方式： npm install hexo –no-optionalnpm uninstall hexo + npm install hexo –no-optionalnpm uninstall hexo-cli -g + npm install hexo-cli -g 最后查找资料得到的解决方案： 首先我们找到全局hexo的安装目录 找到文件dtrace-provider.js 注释如下内容:12345678910111213141516 var builds = [&apos;Release&apos;, &apos;default&apos;, &apos;Debug&apos;];for (var i in builds) &#123; try &#123; var binding = require(&apos;./build/&apos; + builds[i] + &apos;/DTraceProviderBindings&apos;); DTraceProvider = binding.DTraceProvider; break; &#125; catch (e) &#123; // if the platform looks like it _should_ have DTrace // available, log a failure to load the bindings. if (process.platform == &apos;darwin&apos; || process.platform == &apos;sunos&apos; || process.platform == &apos;freebsd&apos;) &#123; console.error(e); &#125; &#125;&#125; 更换主题现在网站上的主题是默认的，既然是打造属于自己的小窝，必然要考虑换一个更好看的样式了~~在经过仔细比对之后，选择了可以适配网页端和手机端的特色主题yilia，相信自己的审美哦^_^列出排名前三的主题： 1.https://github.com/iissnan/hexo-theme-next 3510个star。2.https://github.com/litten/hexo-theme-yilia 1703个star。3.https://github.com/TryGhost/Casper 679个star 具体操作步骤： 1. 克隆项目到本地(任意一个不是在博客文件夹里的地址均可)：这里我用github克隆的，与控制台的命令语句效果相同： git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia 克隆结束后，将克隆文件夹名更改为 yilia，并放于之前所建目录下的/themes/下，与landscape并列。 2. 修改./_config.yml文件： theme: yilia //默认为landscape 3. 修改themes/yilia/_config.yml文件： 注：根据自己的实际情况做调整：动画效果、友情链接、博友回复等等。 4. 查看效果更改主题之后可以使用命令 hexo server 打开本地服务，再次登录 http://localhost:4000/ 查看效果。 Github部署这里连着上一篇博客，将搭建好的网站通过修改配置，完成在github上的部署。 1. Github设置修改./_config.yml文件： deploy: type: git repository: https://github.com/Killy-LIU/killy-liu.github.io.git branch: master 注：在hexo3.x版本下，type应填git，而非github；冒号后面都有一个英文的空格，不然会报错。 2. 部署部署命令为： hexo clean (清理public文件夹，不需要经常用)hexo generatehexo deploy 但我的上一条命令 hexo deploy 报错，因而采用下面的命令： npm install hexo-deployer-git–savehexo deploy 跳坑1：理论上应该部署成功，可是点击网页出现404，发现网页没有对应到我设置的网站上。 百度一下，需要将CNAME，LICENSE，README.md 放在source文件夹下，部署时才会一起传到github上。 重新运行 hexo generatehexo deploy 部署成功^_^ 跳坑2：好多博客中写先搭建hexo并选择主题，后部署与github。曾经试过用github将上一期得到的内容直接下载下来，将这里的内容拷贝到文件夹内，但启动时报错：[rejected] master -&gt; master (non-fast-forward)。原因是两个都是master，有冲突。","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"Hexo","slug":"Hexo","permalink":"http://blog.killyliu.com/tags/Hexo/"}]},{"title":"博客搭建(1)--使用Github搭建个人博客","date":"2017-04-04T05:59:17.000Z","path":"2017/04/04/博客搭建-1-使用Github搭建个人博客/","text":"&ensp;ps：因为最近手误删了两次csdn博客，因而决定在个人博客上也备份一份/(ㄒoㄒ)/~~ 基本准备 github账号：可以起一个有意义的名字哦&emsp;&ensp;链接地址： https://github.com 域名购买：可以在腾讯云或者阿里云上购买一个域名（都有针对学生的优惠）&emsp;&ensp;腾讯云地址：https://www.qcloud.com/?fromSource=gwzcw.5677.5677.5677&emsp;&ensp;阿里云链接地址：https://www.aliyun.com/?utm_medium=text&amp;utm_source=bdbrand&amp;utm_campaign=bdbrand&amp;utm_content=se_32492 创建页面仓库链接地址：https://github.com/new填写相应的信息：仓库名，描述，public，可选初始化信息。 创建成功之后点击设置，可以看到具体的信息： 下拉并点击主题选择，可以根据自己的喜好设置*（注：这里选择的模板都是jekyll的，之后会调整到hexo）： 完成后点击设置可以看到网站链接，便可以访问自己的网站啦啦啦~ 绑定域名跳坑：之前已经拥有了域名：https://killy-liu.github.io/killyliu.github.io/，发现重复了信息，因此修改自己的repo名与自己的名字一样，这里都改为killy-liu.github.io,地址即变为https://killy-liu.github.io/，指向刚刚构建好的页面。 现在需要在根目录下创建一个CNAME的文件，里面写自己的地址，www.killyliu.com，之后访问内容即会重定向到自己这个地址。与此同时，需要进入云服务中设置域名解析。这里我用的是腾讯云服务。在记录管理中对添加域名记录，如下图所示。 在添加完成之后用控制台输入ping命令，查看是否通顺。 试着访问http://www.killyliu.com/，即可看到自己的第一个博客页面^_^ 下一步操作为设置博客样式以及完善内容，并且在思考之后将个人链接由 http://www.killyliu.com 转为 http://blog.killyliu.com 很抱歉之前不能点击链接~~","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"Github","slug":"Github","permalink":"http://blog.killyliu.com/tags/Github/"}]},{"title":"过善于思考的人生，别总选易走的路","date":"2017-03-30T12:31:20.000Z","path":"2017/03/30/过善于思考的人生，别总选易走的路/","text":"&emsp;&emsp;昨天去闺蜜家玩，两人不知不觉聊到了生活方向这个问题，感触颇深，决定写篇随笔记录一下~ &emsp;&emsp;洋学习影视表演专业，现在自己开起了服装网店，日子看起来即使不是特别潇洒也还算自由自在。其实周围好多人都有疑惑，看似不搭调的两个人是如何成为闺蜜的。这里顺便解释一下，我俩是小学同学，到现在已经有十余载的年岁了，虽然走的路不同，但一种似亲情的友谊是与学识经历这些关系不大的。 &emsp;&emsp;回想之前她在化大当老师的时候，就总在业余时间做兼职，两人见面基本都会谈起将来道路选择问题。没有人是真正轻松的，我的付出在于这些年的努力学习，而她的辛苦则体现在各种人际社会关系的处理。轻松欢乐的表面背后，都是不为人知的付出。 &emsp;&emsp;这次，聊到了将来的工作选择上，洋又一次点醒了我。大四时候曾想过自己创业，但在了解一系列流程操作之后发现前路坎坷迷茫而毅然选择了放弃，只想着安安稳稳找家国企有个户口就好。不求轰轰烈烈，只求平平淡淡。现在并不是说这个想法不好，只是缺少了一种趁着年轻勇于奋斗的拼劲。如果二十多岁就过着养老生活，岂不白白浪费青春年华？ &emsp;&emsp;在北京两个非常现实的问题：一是户口，二是住房。现在想起大三时的自己还真的是任性，借着有出国留学经历就觉得即使不读研也可以在企业中风生水起。当时固执地坚持着保不了研就工作的理念，庆幸自己的成绩帮自己选了一条不至于后悔的路，离户口和住房更近了一步。而前一阵子炒饭传给我一张自己写的大二规划的照片，不禁感慨，原来大二自己的思想已经如此成熟了，而且再次体会到思考与规划的价值所在。 &emsp;&emsp;两周前和梦莹聊到她的规划，在企业里做金融方面的计算机实习或工作，空闲时间再自己搭个网站，逐步运营起来~相较而言梦莹的生活更加潇洒，寻找自己喜欢的城市呆十年八年，不用被太多的身外之物所牵绊。奈何自己做不到这么洒脱，旅游是一种放空心灵的方式，但它于我只能是一种附属而非生活。 &emsp;&emsp;今天项目组开会时候调侃道我们不断思考并发task归根到底还是因为穷，如果真能有几百TB级的服务器就都不是事了。穷则思变，而善思则掌局。既然选择了在北京发展，又并非含着金汤匙出生的公主，就应该认真对待生活，仔细规划发展道路。即使没有太大的抱负要感天动地，也不能抱着得过且过的思想，毕竟能挥霍的日子并不多了。 &emsp;&emsp;回到之前的现实状况：户口方面存在两个选择：（1）找国企或者央企，以应届毕业生的身份解决北京户口；（2）出国留学，用海外学位证换外企的北京户口指标。而住房方面现在只能总结一个字：穷。之前网上流行的一个段子：“最近用自己月薪3000攒下的1W，加老爸给的100W，刚刚好付了首付”，而现在更多的是“我真的还想再活五百年”。 &emsp;&emsp;痛定思痛，唯有创新。昨天刘洋向我介绍了好多小型的辅助工具：或微信埋雷抢红包，或批量自动添加好友，或接活帮小公司维护网站。。。在大企业中干活终究是个螺丝钉，还或许是备用的；而自己拥有能做主的事业才是真实掌握在手中的财富。虽说条条大路通罗马，但贫富差距也随之越来越大。 &emsp;&emsp;不觉间已经写了这么多，最后定几个小目标吧：&emsp;&emsp;&emsp;1. 依然坚持每天背单词看阅读打卡；&emsp;&emsp;&emsp;2. 从现在起每想到一个新鲜的idea立即做记录；&emsp;&emsp;&emsp;3. 每周为博客添一点色彩：不论是技术文章、生活随笔、或周边风景；&emsp;&emsp;&emsp;4. 每周看一篇关于人际交流或职场生活的文章；&emsp;&emsp;&emsp;5. 每月涉猎一个自己不熟悉的领域知识；&emsp;&emsp;&emsp;6. 找工作时，对比选择一个发展前景广并切实符合自己兴趣的公司。&emsp;&emsp;ps:其实还有一个大目标：我要减肥！！！/(ㄒoㄒ)/~","tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.killyliu.com/tags/随笔/"}]},{"title":"走在青春的路上","date":"2017-03-28T04:05:59.000Z","path":"2017/03/28/走在青春的路上/","text":"&emsp;&emsp;曾经幻想过自己将来的生活：或许能够成为企业中一名核心人物，运筹帷幄；亦或开一间小店平平淡淡过日子，岁月静好；也不排除辗转于世界各地，随遇而安。无论如何，我的青春我做主。 时光&emsp;&emsp;都说岁月无痕，只是不那么明显罢了。回想小时候，可能因为玩具脏了心情不爽就大哭一场，一切都是那么随性而为之。而当身上肩负的责任越来越多之后，正如邓紫棋歌中所唱，“你的笑只是你穿的保护色”，有时照顾他人的情绪要多于自己，越来越明白为什么人们总是怀念童年了。&emsp;&emsp;而人生没有如果，穿梭时光的机器属于大雄和叮当猫，但不属于我们。有时觉得时间一分一秒都是那么漫长，有时又不禁感慨时间流逝速度之快，并非是时光的魔法，一切均由心生。。。 经历&emsp;&emsp;“似水流年或沧海桑田，总是一眨眼消失在转身的那瞬间；沿途流逝的画面，时光如风掠过了双眼，阡陌稻田，远山云烟”。这些年，我们走过的路、看过的风景，都逐渐化作了经历，不知不觉间影响着为人与处事风格，或成熟稳重，或举步生风。&emsp;&emsp;懵懂时的好奇，悸动时的冲动，成熟时的稳重，都为成长的路上增添了许多色彩，而我也愈发喜欢这样的生活，这样的自己。经历过春夏秋冬的洗礼，体味过朝阳夕下的轮回，渐渐懂得了何时该温婉，何时该冷傲，何时该耀眼，何时该淡然。 梦想&emsp;&emsp;如果说杰伦的《梦想启动》充满积极正能量的话，范范《最初的梦想》则道明了路途中的坎坷与荆棘。古有“长风破浪会有时，直挂云帆济苍海”，今有“既然选择了远方，便只顾风雨兼程”。虽说三千繁华，弹指刹那，但掌握在自己手中的岁月不过百年而已。既已知晓，又如何任时光蹉跎？&emsp;&emsp;仰望星空与脚踏实地，永恒不变的主题，又有谁真正能问心无愧。合抱之木，生于毫末；九层之合，起于垒土；千里之行，始于足下。","tags":[{"name":"随笔","slug":"随笔","permalink":"http://blog.killyliu.com/tags/随笔/"}]},{"title":"Hello World","date":"2017-03-27T13:11:17.000Z","path":"2017/03/27/hello-world/","text":"保留所有程序猿的Hello World情节~~ Hexo使用Create a new post1$ hexo new \"My New Post\" Run server1$ hexo server Generate static files1$ hexo generate Deploy to remote sites1$ hexo deploy","tags":[{"name":"技术","slug":"技术","permalink":"http://blog.killyliu.com/tags/技术/"},{"name":"随感","slug":"随感","permalink":"http://blog.killyliu.com/tags/随感/"}]}]